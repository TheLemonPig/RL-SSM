{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "15pAfwr1UubsHZylyU9tEkm_XdOTBgpHa",
      "authorship_tag": "ABX9TyORzGwUPsYNdOtFCkdJgJbN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheLemonPig/RL-SSM/blob/main/RLWM_SSM_differentiable.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRLyVFDSKhgj"
      },
      "outputs": [],
      "source": [
        "!pip install 'pymc>=5.9'\n",
        "!pip install numpyro\n",
        "!pip install git+https://github.com/AlexanderFengler/ssm-simulators@main\n",
        "!pip install git+https://github.com/AlexanderFengler/LANfactory"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pymc as pm\n",
        "import numpy as np\n",
        "import random, pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pytensor\n",
        "import pytensor.tensor as pt\n",
        "import arviz as az\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import ssms\n",
        "from ssms.basic_simulators.simulator import simulator\n",
        "import lanfactory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWM0hvr8KxTp",
        "outputId": "4b357d85-75a0-4b22-8945-cfd500575c8a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "passing 1\n",
            "wandb not available\n",
            "wandb not available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "random.seed(0)"
      ],
      "metadata": {
        "id": "jAqPunB5QLlv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SSM for PyTensor Pre-Prep"
      ],
      "metadata": {
        "id": "x7yJSsXtgOwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ssms.config.model_config.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVe-xajjydVg",
        "outputId": "3ae9b09e-c5b3-4dec-9fc7-90344ccd48e6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['ddm', 'ddm_legacy', 'angle', 'weibull', 'levy', 'levy_angle', 'full_ddm', 'gamma_drift', 'gamma_drift_angle', 'ds_conflict_drift', 'ds_conflict_drift_angle', 'ornstein', 'ornstein_angle', 'ddm_sdv', 'lba_3_v1', 'lba_angle_3_v1', 'rlwm_lba_race_v1', 'race_2', 'race_no_bias_2', 'race_no_z_2', 'race_no_bias_angle_2', 'race_no_z_angle_2', 'race_3', 'race_no_bias_3', 'race_no_z_3', 'race_no_bias_angle_3', 'race_no_z_angle_3', 'race_4', 'race_no_bias_4', 'race_no_z_4', 'race_no_bias_angle_4', 'race_no_z_angle_4', 'lca_3', 'lca_no_bias_3', 'lca_no_z_3', 'lca_no_bias_angle_3', 'lca_no_z_angle_3', 'lca_4', 'lca_no_bias_4', 'lca_no_z_4', 'lca_no_bias_angle_4', 'lca_no_z_angle_4', 'ddm_par2', 'ddm_par2_no_bias', 'ddm_par2_conflict_gamma_no_bias', 'ddm_par2_angle_no_bias', 'ddm_par2_weibull_no_bias', 'ddm_seq2', 'ddm_seq2_no_bias', 'ddm_seq2_conflict_gamma_no_bias', 'ddm_seq2_angle_no_bias', 'ddm_seq2_weibull_no_bias', 'ddm_mic2_adj', 'ddm_mic2_adj_no_bias', 'ddm_mic2_adj_conflict_gamma_no_bias', 'ddm_mic2_adj_angle_no_bias', 'ddm_mic2_adj_weibull_no_bias', 'ddm_mic2_ornstein', 'ddm_mic2_ornstein_no_bias', 'ddm_mic2_ornstein_conflict_gamma_no_bias', 'ddm_mic2_ornstein_angle_no_bias', 'ddm_mic2_ornstein_weibull_no_bias', 'ddm_mic2_multinoise_no_bias', 'ddm_mic2_multinoise_conflict_gamma_no_bias', 'ddm_mic2_multinoise_angle_no_bias', 'ddm_mic2_multinoise_weibull_no_bias', 'ddm_mic2_leak', 'ddm_mic2_leak_no_bias', 'ddm_mic2_leak_conflict_gamma_no_bias', 'ddm_mic2_leak_angle_no_bias', 'ddm_mic2_leak_weibull_no_bias', 'tradeoff_no_bias', 'tradeoff_angle_no_bias', 'tradeoff_weibull_no_bias', 'tradeoff_conflict_gamma_no_bias', 'weibull_cdf', 'full_ddm2', 'ddm_mic2_ornstein_no_bias_no_lowdim_noise', 'ddm_mic2_ornstein_angle_no_bias_no_lowdim_noise', 'ddm_mic2_ornstein_weibull_no_bias_no_lowdim_noise', 'ddm_mic2_ornstein_conflict_gamma_no_bias_no_lowdim_noise', 'ddm_mic2_leak_no_bias_no_lowdim_noise', 'ddm_mic2_leak_angle_no_bias_no_lowdim_noise', 'ddm_mic2_leak_weibull_no_bias_no_lowdim_noise', 'ddm_mic2_leak_conflict_gamma_no_bias_no_lowdim_noise'])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ssms_model = 'lba_angle_3_v1'\n",
        "model_config = ssms.config.model_config[ssms_model]\n",
        "param_theta = np.array([0.5, 0.3, 0.2, 0.5, 0.2, 0.0])\n",
        "res = simulator(\n",
        "                param_theta,\n",
        "                model=ssms_model,\n",
        "                n_samples=2000,\n",
        "                delta_t=0.001,\n",
        "                max_t=5,\n",
        "                )\n",
        "network_config = pickle.load(open('/content/drive/MyDrive/hssm_rlwm/LANs/lba_angle_3_v1_torch__network_config.pickle', 'rb'))\n",
        "model_file_path = '/content/drive/MyDrive/hssm_rlwm/LANs/lba_angle_3_v1_torch_state_dict.pt'\n",
        "torch_mlp = lanfactory.trainers.torch_mlp.LoadTorchMLPInfer(model_file_path = model_file_path,\n",
        "                                                network_config = network_config,\n",
        "                                                input_dim = 6 + 2) ## 6 is a hard-coded value for lba_angle_3_v1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcyubNNtQSZ5",
        "outputId": "c86ba0cb-afea-46a1-a933-e589178fb3cf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting network type to \"lan\" or \"cpn\" based on train_output_type. \n",
            "Note: This is only a default setting, and can be overwritten by the network_type argument.\n",
            "tanh\n",
            "tanh\n",
            "tanh\n",
            "linear\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights_0 = torch_mlp.net.state_dict()['layers.0.weight'].cpu().numpy().astype(np.float32).T\n",
        "weights_1 = torch_mlp.net.state_dict()['layers.2.weight'].cpu().numpy().astype(np.float32).T\n",
        "weights_2 = torch_mlp.net.state_dict()['layers.4.weight'].cpu().numpy().astype(np.float32).T\n",
        "weights_3 = torch_mlp.net.state_dict()['layers.6.weight'].cpu().numpy().astype(np.float32).T\n",
        "biases_0 = torch_mlp.net.state_dict()['layers.0.bias'].cpu().numpy().astype(np.float32).T\n",
        "biases_1 = torch_mlp.net.state_dict()['layers.2.bias'].cpu().numpy().astype(np.float32).T\n",
        "biases_2 = torch_mlp.net.state_dict()['layers.4.bias'].cpu().numpy().astype(np.float32).T\n",
        "biases_3 = torch_mlp.net.state_dict()['layers.6.bias'].cpu().numpy().astype(np.float32).T"
      ],
      "metadata": {
        "id": "uMEWZYXca4rP"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zVA4Nq2J4Jr"
      },
      "source": [
        "##PyTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk_U1m5SSsJi"
      },
      "source": [
        "####Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "btpenR8nSxm6"
      },
      "outputs": [],
      "source": [
        "def rlwm_step(dC, dR, pA, pG, pP, dq_RL, dq_WM):\n",
        "    \"\"\"\n",
        "    rlwm_step: calculate a single RLWM step\n",
        "    (n_participants, n_choices, n_blocks, n_stimuli)\n",
        "    dC: Choices (data)\n",
        "    dR: Rewards (data)\n",
        "    pA: Alphas (parameter)\n",
        "    pG: Gammas (parameter)\n",
        "    pP: Phis (parameter)\n",
        "    dq_RL: RL Qs (data)\n",
        "    dq_WM: WM Qs (data)\n",
        "    \"\"\"\n",
        "    cond = pt.switch(pt.lt(dq_RL, dR), 1, 0)\n",
        "    dq_RL += (cond + (1.0 - cond) * pG) * pA * (dR - dq_RL) * dC\n",
        "    dq_WM += (cond + (1.0 - cond) * pG) * 1.0 * (dR - dq_WM) * dC\n",
        "    dq_WM += pP * (1 / dR.shape[1] - dq_WM)\n",
        "    return [dq_RL, dq_WM]\n",
        "\n",
        "def rlwm_scan(dC, dR, pA, pG, pP, dq_RL, dq_WM):\n",
        "    \"\"\"\n",
        "    rlwm_scan: calculate a RLWM Q-Values\n",
        "    (n_trials, n_participants, n_choices, n_blocks, n_stimuli)\n",
        "    dC: Choices (data)\n",
        "    dR: Rewards (data)\n",
        "    pA: Alphas (parameter)\n",
        "    pG: Gammas (parameter)\n",
        "    pP: Phis (parameter)\n",
        "    dq_RL: RL Qs (data)\n",
        "    dq_WM: WM Qs (data)\n",
        "    \"\"\"\n",
        "    ([dQ_RL, dQ_WM], _) = pytensor.scan(rlwm_step, sequences=[dC, dR, pA, pG, pP], non_sequences=[], outputs_info=[dq_RL, dq_WM])\n",
        "    shape = dC.shape\n",
        "    n_trials_m1 = shape[0]-1\n",
        "    dQ_RL = pt.subtensor.set_subtensor(pt.repeat(dq_RL.reshape((1,shape[1],shape[2],shape[3],shape[4])),shape[0],axis=0)[-n_trials_m1:], dQ_RL[:n_trials_m1])\n",
        "    dQ_WM = pt.subtensor.set_subtensor(pt.repeat(dq_WM.reshape((1,shape[1],shape[2],shape[3],shape[4])),shape[0],axis=0)[-n_trials_m1:], dQ_WM[:n_trials_m1])\n",
        "    return dQ_RL, dQ_WM\n",
        "\n",
        "\n",
        "def pytensor_softmax(Qs, pB):\n",
        "    \"\"\"\n",
        "    rlwm_softmax: calculate probabilities using a tempered softmax over Q-Values\n",
        "\n",
        "    Qs: Q-Values (data)\n",
        "    pB: Betas (parameter)\n",
        "    \"\"\"\n",
        "    shape = Qs.shape\n",
        "    tempered_qs = pt.mul(Qs,pB)\n",
        "    qs_max = pt.max(tempered_qs,axis=2)\n",
        "    qs_max = pt.repeat(qs_max.reshape((shape[0], shape[1], 1, shape[3], shape[4])), shape[2], axis=2)\n",
        "    numerator = pt.exp(tempered_qs - qs_max)\n",
        "    denominator = pt.sum(numerator, axis=2)\n",
        "    denominator = pt.repeat(denominator.reshape((shape[0], shape[1], 1, shape[3], shape[4])), shape[2], axis=2)\n",
        "    Ps = numerator / denominator\n",
        "    return Ps\n",
        "\n",
        "def rlwm_policy(dC, dq_RL, dq_WM, pB, pC, pE, pR, set_sizes):\n",
        "    weight = pR * pt.clip(pC/set_sizes, 0, 1)\n",
        "    Ps_RL = pytensor_softmax(dq_RL, pB)\n",
        "    Ps_WM = pytensor_softmax(dq_WM, pB)\n",
        "    pol = weight * Ps_WM + (1.0 - weight) * Ps_RL\n",
        "    pol_final = (1.0 - pE) * pol + pE * 1.0/dC.shape[2]\n",
        "    return pol_final\n",
        "\n",
        "def pytensor_lan(weights_0,weights_1,weights_2,weights_3,biases_0,biases_1,biases_2,biases_3,in_):\n",
        "    # neural net\n",
        "    hid0 = pt.tanh(pt.dot(in_,weights_0)+biases_0)\n",
        "    hid1 = pt.tanh(pt.dot(hid0, weights_1)+biases_1)\n",
        "    hid2 = pt.tanh(pt.dot(hid1, weights_2)+biases_2)\n",
        "    out = pt.dot(hid2, weights_3)+biases_3\n",
        "    return out\n",
        "\n",
        "def scan_to_lan_shape(dC, pol_final):\n",
        "    pssmV = pol_final.dimshuffle((1, 3, 0, 2, 4)).reshape((-1, dC.shape[2]))\n",
        "    return pssmV\n",
        "\n",
        "def rlwmssm_likelihood(dC, dq_RL, dq_WM, pB, pC, pE, pR, set_sizes, pssmA, pssmZ, pssmT, dssmC, dssmRT, weights_0,weights_1,weights_2,weights_3,biases_0,biases_1,biases_2,biases_3):\n",
        "    \"\"\"\n",
        "    rlwm_likelihood: calculate RLWM Likelihoods from precomputed Q-Values\n",
        "\n",
        "    dC: Choices (data)\n",
        "    dq_RL: Precomputed RL Qs (data)\n",
        "    dq_WM: Precomputed WM Qs (data)\n",
        "    pB: Betas (parameter)\n",
        "    pC: Working Memory Capacities (parameter)\n",
        "    pE: Epsilons (parameter)\n",
        "    pR: Rhos (parameter)\n",
        "    set_sizes: set sizes for each participant block (data)\n",
        "    \"\"\"\n",
        "    # pol_final: (n_trials, n_participants, n_choices, n_blocks, n_stimuli)\n",
        "    pol_final = rlwm_policy(dC, dq_RL, dq_WM, pB, pC, pE, pR, set_sizes)\n",
        "    pssmV = scan_to_lan_shape(dC, pol_final)\n",
        "    # What do I do with choices and rts? How do I put them through the LAN with the parameters?\n",
        "    in_ = pt.concatenate([pssmV, pssmA.reshape((-1,1)), pssmZ.reshape((-1,1)), pssmT.reshape((-1,1)), dssmRT.reshape((-1,1)), dssmC.reshape((-1,1))], axis=1)\n",
        "    ll = pytensor_lan(weights_0,weights_1,weights_2,weights_3,biases_0,biases_1,biases_2,biases_3,in_)\n",
        "    return ll\n",
        "\n",
        "\n",
        "def rlwmssm_recovery(dq_RL, dq_WM, dC, dR, pA, pB, pC, pE, pG, pP, pR, set_sizes, pssmA, pssmZ, pssmT, dssmC, dssmRT, weights_0,weights_1,weights_2,weights_3,biases_0,biases_1,biases_2,biases_3):\n",
        "    \"\"\"\n",
        "    rlwm_likelihood: calculate RLWM Likelihoods given over a valid set of parameters and complete dataset of choices, rewards, and set sizes\n",
        "\n",
        "    dC: Choices (data)\n",
        "    dq_RL: Precomputed RL Qs (data)\n",
        "    dq_WM: Precomputed WM Qs (data)\n",
        "    pB: Betas (parameter)\n",
        "    pC: Working Memory Capacities (parameter)\n",
        "    pE: Epsilons (parameter)\n",
        "    pR: Rhos (parameter)\n",
        "    set_sizes: set sizes for each participant block (data)\n",
        "    \"\"\"\n",
        "    dq_RL, dq_WM = rlwm_scan(dC, dR, pA, pG, pP, dq_RL, dq_WM)\n",
        "    likelihood = rlwmssm_likelihood(dC, dq_RL, dq_WM, pB, pC, pE, pR, set_sizes, pssmA, pssmZ, pssmT, dssmC, dssmRT, weights_0,weights_1,weights_2,weights_3,biases_0,biases_1,biases_2,biases_3)\n",
        "    return likelihood"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjZWgiJOSyb3"
      },
      "source": [
        "####Compilers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "UTPXZtEOBbuZ"
      },
      "outputs": [],
      "source": [
        "def rlwm_step_compile():\n",
        "    dC3 = pt.dtensor4(\"dC3\")\n",
        "    dR3 = pt.dtensor4(\"dR3\")\n",
        "    dq_RL3 = pt.dtensor4(\"dq_RL3\")\n",
        "    dq_WM3 = pt.dtensor4(\"dq_WM3\")\n",
        "    pA3 = pt.dtensor4(\"pA3\")\n",
        "    pG3 = pt.dtensor4(\"pG3\")\n",
        "    pP3 = pt.dtensor4(\"pP3\")\n",
        "\n",
        "    dq_RL, dq_WM = rlwm_step(dC3, dR3, pA3, pG3, pP3, dq_RL3, dq_WM3)\n",
        "    rlwm_step_func = pytensor.function(inputs=[dC3, dR3, pA3, pG3, pP3, dq_RL3, dq_WM3], outputs=[dq_RL, dq_WM])\n",
        "\n",
        "    return rlwm_step_func\n",
        "\n",
        "\n",
        "def rlwm_scan_compile():\n",
        "    dC4 = pt.dtensor5(\"dC4\")\n",
        "    dR4 = pt.dtensor5(\"dR4\")\n",
        "    dq_RL3 = pt.dtensor4(\"dq_RL3\")\n",
        "    dq_WM3 = pt.dtensor4(\"dq_WM3\")\n",
        "    pA4 = pt.dtensor5(\"pA4\")\n",
        "    pG4 = pt.dtensor5(\"pG4\")\n",
        "    pP4 = pt.dtensor5(\"pP4\")\n",
        "\n",
        "    dq_RL, dq_WM = rlwm_scan(dC4, dR4, pA4, pG4, pP4, dq_RL3, dq_WM3)\n",
        "    rlwm_step_func = pytensor.function(inputs=[dC4, dR4, pA4, pG4, pP4, dq_RL3, dq_WM3], outputs=[dq_RL, dq_WM])\n",
        "\n",
        "    return rlwm_step_func\n",
        "\n",
        "\n",
        "def pytensor_softmax_compile():\n",
        "    Qs = pt.dtensor5('Qs')\n",
        "    B = pt.dtensor5('B')\n",
        "\n",
        "    Ps = pytensor_softmax(Qs, B)\n",
        "    Ps_func = pytensor.function(inputs=[Qs, B], outputs=Ps)\n",
        "\n",
        "    return Ps_func\n",
        "\n",
        "\n",
        "def rlwmssm_likelihood_compile():\n",
        "    dC4 = pt.dtensor5(\"dC4\")\n",
        "    dq_RL4 = pt.dtensor5(\"dq_RL4\")\n",
        "    dq_WM4 = pt.dtensor5(\"dq_WM4\")\n",
        "    pB4 = pt.dtensor5(\"pB4\")\n",
        "    pC4 = pt.dtensor5(\"pC4\")\n",
        "    pE4 = pt.dtensor5(\"pE4\")\n",
        "    pR4 = pt.dtensor5(\"pR4\")\n",
        "    set_sizes = pt.dtensor5(\"set_sizes\")\n",
        "    pssmA = pt.dvector(\"pssmA\")\n",
        "    pssmZ = pt.dvector(\"pssmZ\")\n",
        "    pssmT = pt.dvector(\"pssmT\")\n",
        "    dssmC = pt.dvector(\"dssmC\")\n",
        "    dssmRT = pt.dvector(\"dssmRT\")\n",
        "    weights_0 = pt.dmatrix(\"weights_0\")\n",
        "    weights_1 = pt.dmatrix(\"weights_1\")\n",
        "    weights_2 = pt.dmatrix(\"weights_2\")\n",
        "    weights_3 = pt.dmatrix(\"weights_3\")\n",
        "    biases_0 = pt.dvector(\"biases_0\")\n",
        "    biases_1 = pt.dvector(\"biases_1\")\n",
        "    biases_2 = pt.dvector(\"biases_2\")\n",
        "    biases_3 = pt.dvector(\"biases_3\")\n",
        "    likelihood = rlwmssm_likelihood(dC4, dq_RL4, dq_WM4, pB4, pC4, pE4, pR4, set_sizes, pssmA, pssmZ, pssmT, dssmC, dssmRT, weights_0,weights_1,weights_2,weights_3,biases_0,biases_1,biases_2,biases_3)\n",
        "    rlwm_likelihood_func = pytensor.function(inputs=[dC4, dq_RL4, dq_WM4, pB4, pC4, pE4, pR4, set_sizes, pssmA, pssmZ, pssmT, dssmC, dssmRT, weights_0,weights_1,weights_2,weights_3,biases_0,biases_1,biases_2,biases_3], outputs=likelihood)\n",
        "\n",
        "    return rlwm_likelihood_func\n",
        "\n",
        "def rlwmssm_recovery_compile():\n",
        "    dq_RL = pt.dtensor4(\"dq_RL\")\n",
        "    dq_WM = pt.dtensor4(\"dq_WM\")\n",
        "    dC = pt.dtensor5(\"dC\")\n",
        "    dR = pt.dtensor5(\"dR\")\n",
        "    pA = pt.dtensor5(\"pA\")\n",
        "    pB = pt.dtensor5(\"pB\")\n",
        "    pC = pt.dtensor5(\"pC\")\n",
        "    pE = pt.dtensor5(\"pE\")\n",
        "    pG = pt.dtensor5(\"pG\")\n",
        "    pP = pt.dtensor5(\"pP\")\n",
        "    pR = pt.dtensor5(\"pR\")\n",
        "    set_sizes = pt.dtensor5(\"set_sizes\")\n",
        "    pssmA = pt.dvector(\"pssmA\")\n",
        "    pssmZ = pt.dvector(\"pssmZ\")\n",
        "    pssmT = pt.dvector(\"pssmT\")\n",
        "    dssmC = pt.dvector(\"dssmC\")\n",
        "    dssmRT = pt.dvector(\"dssmRT\")\n",
        "    weights_0 = pt.dmatrix(\"weights_0\")\n",
        "    weights_1 = pt.dmatrix(\"weights_1\")\n",
        "    weights_2 = pt.dmatrix(\"weights_2\")\n",
        "    weights_3 = pt.dmatrix(\"weights_3\")\n",
        "    biases_0 = pt.dvector(\"biases_0\")\n",
        "    biases_1 = pt.dvector(\"biases_1\")\n",
        "    biases_2 = pt.dvector(\"biases_2\")\n",
        "    biases_3 = pt.dvector(\"biases_3\")\n",
        "\n",
        "    likelihood = rlwmssm_recovery(dq_RL, dq_WM, dC, dR, pA, pB, pC, pE, pG, pP, pR, set_sizes, pssmA, pssmZ, pssmT, dssmC, dssmRT, weights_0,weights_1,weights_2,weights_3,biases_0,biases_1,biases_2,biases_3)\n",
        "    rlwm_recovery_func = pytensor.function(inputs=[dq_RL, dq_WM, dC, dR, pA, pB, pC, pE, pG, pP, pR, set_sizes, pssmA, pssmZ, pssmT, dssmC, dssmRT, weights_0,weights_1,weights_2,weights_3,biases_0,biases_1,biases_2,biases_3], outputs=likelihood)\n",
        "\n",
        "    return rlwm_recovery_func"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.max(np.repeat(np.array([0,1,2,3]),3).reshape((-1,3)),axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ie7ggh92j_mc",
        "outputId": "a64e95db-699b-4910-fbbd-6eb652425dec"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tests"
      ],
      "metadata": {
        "id": "h4JspSHJgAjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rlwm_step_test():\n",
        "    n_participants = 6\n",
        "    n_choices = 3\n",
        "    n_stimuli = [4, 5, 6, 7, 8]\n",
        "    max_stimuli = max(n_stimuli)\n",
        "    n_blocks = 5\n",
        "    shape4 = (n_participants, n_choices, n_blocks, max_stimuli)\n",
        "\n",
        "    dC4_ = np.random.randint(low=0, high=n_choices, size=shape4)\n",
        "    dR4_ = np.random.randint(low=0, high=1, size=shape4)\n",
        "    pA4_ = np.ones(shape4) * 0.1\n",
        "    pG4_ = np.ones(shape4) * 0.9\n",
        "    pP4_ = np.ones(shape4) * 1.0\n",
        "    mask = np.ones(shape4)\n",
        "    cond = np.ones(shape4)\n",
        "    dQ4_ = np.ones(shape4) * 1/n_choices\n",
        "    dq_RL4_ = np.ones(shape4) * 1/n_choices\n",
        "    dq_WM4_ = np.ones(shape4) * 1/n_choices\n",
        "\n",
        "    test_func = rlwm_step_compile()\n",
        "\n",
        "    return test_func(dC4_, dR4_, pA4_, pG4_, pP4_, dq_RL4_, dq_WM4_)\n",
        "\n",
        "\n",
        "def rlwm_scan_test():\n",
        "    n_trials = 23\n",
        "    n_participants = 6\n",
        "    n_choices = 3\n",
        "    n_stimuli = [4, 5, 6, 7, 8]\n",
        "    max_stimuli = max(n_stimuli)\n",
        "    n_blocks = 5\n",
        "    shape5 = (n_trials * max_stimuli, n_participants, n_choices, n_blocks, max_stimuli)\n",
        "\n",
        "    dC5_ = np.random.randint(low=0, high=n_choices, size=shape5)\n",
        "    dR5_ = np.random.randint(low=0, high=1, size=shape5)\n",
        "    dq_RL4_ = np.ones_like(dR5_)[0] * 1 / n_choices\n",
        "    dq_WM4_ = np.ones_like(dR5_)[0] * 1 / n_choices\n",
        "    pA5_ = np.ones_like(dR5_) * 0.1\n",
        "    pG5_ = np.ones_like(dR5_) * 0.9\n",
        "    pP5_ = np.ones_like(dR5_) * 1.0\n",
        "\n",
        "    test_func = rlwm_scan_compile()\n",
        "\n",
        "    return test_func(dC5_, dR5_, pA5_, pG5_, pP5_, dq_RL4_, dq_WM4_)\n",
        "\n",
        "\n",
        "def pytensor_softmax_test():\n",
        "    n_trials = 23\n",
        "    n_participants = 6\n",
        "    n_choices = 3\n",
        "    n_stimuli = [4, 5, 6, 7, 8]\n",
        "    max_stimuli = np.max(n_stimuli)\n",
        "    n_blocks = 5\n",
        "    shape = (n_trials * max_stimuli, n_participants, n_choices, n_blocks, max_stimuli)\n",
        "\n",
        "    Qs = np.ones(shape)\n",
        "    B = np.ones_like(Qs)\n",
        "\n",
        "    test_func = pytensor_softmax_compile()\n",
        "\n",
        "    return test_func(Qs, B)\n",
        "\n",
        "\n",
        "def rlwmssm_likelihood_test():\n",
        "    n_trials = 23\n",
        "    n_participants = 6\n",
        "    n_choices = 3\n",
        "    n_stimuli = [4, 5, 6, 7, 8]\n",
        "    max_stimuli = np.max(n_stimuli)\n",
        "    n_blocks = 5\n",
        "    shape5 = (n_trials * max_stimuli, n_participants, n_choices, n_blocks, max_stimuli)\n",
        "\n",
        "    dC5_ = np.random.randint(low=0, high=n_choices, size=shape5)\n",
        "    dq_RL5_ = - np.ones_like(dC5_) * 1 / n_choices\n",
        "    dq_WM5_ = - np.ones_like(dC5_) * 1 / n_choices\n",
        "    pB5_ = np.ones_like(dC5_) * 1.0\n",
        "    pC5_ = np.ones_like(dC5_) * 4.0\n",
        "    pE5_ = np.ones_like(dC5_) * 0.5\n",
        "    pR5_ = np.ones_like(dC5_) * 0.8\n",
        "    set_sizes_ = np.repeat(np.tile(n_stimuli, (shape5[0], shape5[1], shape5[2], 1)).reshape((shape5[0], shape5[1], shape5[2], shape5[3], 1)), shape5[4], axis=4)\n",
        "    pssmA_ = np.ones((shape5[0]*shape5[1]*shape5[3]*shape5[4])) * 0.5\n",
        "    pssmZ_ = np.ones((shape5[0]*shape5[1]*shape5[3]*shape5[4])) * 0.5\n",
        "    pssmT_ = np.ones((shape5[0]*shape5[1]*shape5[3]*shape5[4])) * 0.5\n",
        "    dssmC_ = np.argmax(dC5_,axis=2).reshape((-1,))\n",
        "    dssmRT_ = np.random.randint(low=1, high=100, size=(shape5[0]*shape5[1]*shape5[3]*shape5[4])) / 25\n",
        "    weights_0_ = weights_0\n",
        "    weights_1_ = weights_1\n",
        "    weights_2_ = weights_2\n",
        "    weights_3_ = weights_3\n",
        "    biases_0_ = biases_0\n",
        "    biases_1_ = biases_1\n",
        "    biases_2_ = biases_2\n",
        "    biases_3_ = biases_3\n",
        "\n",
        "    test_func = rlwmssm_likelihood_compile()\n",
        "\n",
        "    return test_func(dC5_, dq_RL5_, dq_WM5_, pB5_, pC5_, pE5_, pR5_, set_sizes_, pssmA_, pssmZ_, pssmT_, dssmC_, dssmRT_, weights_0_, weights_1_, weights_2_, weights_3_, biases_0_, biases_1_, biases_2_, biases_3_)\n",
        "\n",
        "\n",
        "def rlwmssm_recovery_test():\n",
        "    n_trials = 15\n",
        "    n_participants = 20\n",
        "    n_choices = 3\n",
        "    n_blocks = 22\n",
        "    n_stimuli = [6 for _ in range(n_blocks)]\n",
        "    max_stimuli = max(n_stimuli)\n",
        "    shape = (n_trials * max_stimuli, n_participants, n_choices, n_blocks, max_stimuli)\n",
        "\n",
        "    dq_RL_ = np.ones(shape)[0] * 1.0 / n_choices\n",
        "    dq_WM_ = np.ones(shape)[0] * 1.0 / n_choices\n",
        "\n",
        "    dC_ = np.random.randint(low=0, high=n_choices, size=shape)\n",
        "    dR_ = np.random.randint(low=0, high=1, size=shape)\n",
        "    pA_ = np.ones_like(dC_) * 0.01\n",
        "    pB_ = np.ones_like(dC_) * 1.0\n",
        "    pC_ = np.ones_like(dC_) * 4.0\n",
        "    pE_ = np.ones_like(dC_) * 0.02\n",
        "    pG_ = np.ones_like(dC_) * 0.8\n",
        "    pP_ = np.ones_like(dC_) * 0.3\n",
        "    pR_ = np.ones_like(dC_) * 0.8\n",
        "    set_sizes_ = np.repeat(np.tile(n_stimuli, (shape[0], shape[1], shape[2], 1)).reshape((shape[0], shape[1], shape[2], shape[3], 1)), shape[4], axis=4)\n",
        "\n",
        "    pssmA_ = np.ones((shape[0]*shape[1]*shape[3]*shape[4])) * 0.5\n",
        "    pssmZ_ = np.ones((shape[0]*shape[1]*shape[3]*shape[4])) * 0.5\n",
        "    pssmT_ = np.ones((shape[0]*shape[1]*shape[3]*shape[4])) * 0.5\n",
        "    dssmC_ = np.argmax(dC_,axis=2).reshape((-1,))\n",
        "    dssmRT_ = np.random.randint(low=1, high=100, size=(shape[0]*shape[1]*shape[3]*shape[4])) / 25\n",
        "    weights_0_ = weights_0\n",
        "    weights_1_ = weights_1\n",
        "    weights_2_ = weights_2\n",
        "    weights_3_ = weights_3\n",
        "    biases_0_ = biases_0\n",
        "    biases_1_ = biases_1\n",
        "    biases_2_ = biases_2\n",
        "    biases_3_ = biases_3\n",
        "\n",
        "    test_func = rlwmssm_recovery_compile()\n",
        "\n",
        "    return test_func(dq_RL_, dq_WM_, dC_, dR_, pA_, pB_, pC_, pE_, pG_, pP_, pR_, set_sizes_, pssmA_, pssmZ_, pssmT_, dssmC_, dssmRT_, weights_0_, weights_1_, weights_2_, weights_3_, biases_0_, biases_1_, biases_2_, biases_3_)"
      ],
      "metadata": {
        "id": "Np9NF8wagCI5"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWxAMAkKTFG8"
      },
      "source": [
        "###Run Compilers and Tests here\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUIZzF7pBfZD",
        "outputId": "8adc282b-2754-4a7e-8ac9-bd3015a816ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6, 3, 5, 8), (6, 3, 5, 8))"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "source": [
        "rlwm_step_compile()\n",
        "dq_RL, dq_WM =  rlwm_step_test()\n",
        "dq_RL.shape, dq_WM.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYXuaCJHBpPD",
        "outputId": "6deb97f0-cb7c-43a2-e1f7-91744c187ebd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((184, 6, 3, 5, 8), (184, 6, 3, 5, 8))"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "rlwm_scan_compile()\n",
        "dq_RL, dq_WM = rlwm_scan_test()\n",
        "dq_RL.shape, dq_WM.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Px9mS9IkuAm",
        "outputId": "e3518456-f705-4dd4-a9d5-6fda06a82787"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(184, 6, 3, 5, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ],
      "source": [
        "pytensor_softmax_compile()\n",
        "pytensor_softmax_test().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlJ4zUcvBv9d",
        "outputId": "15bbd380-0a6c-4d13-8af9-3b3da992a9fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44160, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ],
      "source": [
        "rlwmssm_likelihood_compile()\n",
        "rlwmssm_likelihood_test().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-s2eR_RB0XW",
        "outputId": "efd974e7-d6f2-4cd6-fbca-ac65257e78ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(237600,)"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ],
      "source": [
        "rlwmssm_recovery_compile()\n",
        "rlwmssm_recovery_test().flatten().shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generate RLWM-SSM Data"
      ],
      "metadata": {
        "id": "QD6QGamSdehw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "6A447EmYblqB"
      },
      "outputs": [],
      "source": [
        "def gen_trial_seq(set_size, num_rep_per_block):\n",
        "    trials = list()\n",
        "\n",
        "    for stim in np.arange(set_size):\n",
        "        trials.extend([stim]*random.choice(num_rep_per_block))\n",
        "    random.shuffle(trials)\n",
        "\n",
        "    return trials\n",
        "\n",
        "def gen_SR_map(set_size, num_actions):\n",
        "    S_R_map = {}\n",
        "    acts = np.arange(num_actions)\n",
        "\n",
        "    for stim in np.arange(set_size):\n",
        "        S_R_map[stim] = random.choice(acts)\n",
        "\n",
        "    return S_R_map\n",
        "\n",
        "def step_action(s, a, S_R_map):\n",
        "    if a == S_R_map[s]:\n",
        "        rew = 1\n",
        "    else:\n",
        "        rew = 0\n",
        "\n",
        "    return rew\n",
        "\n",
        "def softmax(q_val, beta):\n",
        "    q_val = np.array(q_val)*beta\n",
        "    q_val = q_val - np.max(q_val)\n",
        "    q_val = np.exp(q_val)\n",
        "    q_val = q_val / np.sum(q_val)\n",
        "    return q_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "v7D-Y4SLblqB"
      },
      "outputs": [],
      "source": [
        "def simulate_RLWM(params_list, set_size_list, num_rep_per_block, num_actions, subjs=1):\n",
        "\n",
        "    sub_list = np.arange(subjs)\n",
        "    actions = np.arange(num_actions)\n",
        "\n",
        "    sub_list_sub_id = list()\n",
        "    sub_list_block_num = list()\n",
        "    sub_list_stim = list()\n",
        "    sub_list_actions = list()\n",
        "    sub_list_reward = list()\n",
        "    sub_list_corr = list()\n",
        "    sub_list_stim_ctr = list()\n",
        "    sub_list_set_size = list()\n",
        "    sub_list_rt = list()\n",
        "\n",
        "    for subj in sub_list:\n",
        "        # RLWM parameters\n",
        "        a = params_list[0]\n",
        "        z = params_list[1]\n",
        "        theta = params_list[2]\n",
        "\n",
        "        alpha = params_list[3]\n",
        "        phi = params_list[4]\n",
        "        rho = params_list[5]\n",
        "        gamma = params_list[6]\n",
        "        epsilon = params_list[7]\n",
        "        C = params_list[8]\n",
        "\n",
        "        beta = 100\n",
        "\n",
        "        pol = np.zeros(num_actions)\n",
        "\n",
        "        for bl in range(len(set_size_list)):\n",
        "            #print(\">> block -- \", bl)\n",
        "            set_size = set_size_list[bl]\n",
        "\n",
        "            S_R_map = gen_SR_map(set_size, num_actions)\n",
        "            trials = gen_trial_seq(set_size, num_rep_per_block)\n",
        "\n",
        "            # print(trials)\n",
        "\n",
        "            q_RL = np.ones((set_size, num_actions)) * 1/num_actions\n",
        "            q_WM = np.ones((set_size, num_actions)) * 1/num_actions\n",
        "            weight = rho * min(1, C/set_size)\n",
        "\n",
        "            stim_counter = np.zeros(set_size)\n",
        "\n",
        "            for tr in np.arange(len(trials)):\n",
        "                state = trials[tr]\n",
        "                stim_counter[state] += 1\n",
        "\n",
        "                pol_RL = softmax(q_RL[state, :], beta)\n",
        "                pol_WM = softmax(q_WM[state, :], beta)\n",
        "\n",
        "                pol = weight * pol_WM + (1-weight) * pol_RL\n",
        "\n",
        "                pol_final = (1 - epsilon) * pol + epsilon * np.tile([1/num_actions], num_actions)\n",
        "\n",
        "                param_theta = [pol_final[0], pol_final[1], pol_final[2], a, z, theta] # for lba_angle_3_v1\n",
        "\n",
        "\n",
        "                res = simulator(\n",
        "                    param_theta,\n",
        "                    model='lba_angle_3_v1',\n",
        "                    n_samples=1,\n",
        "                    delta_t=0.001,\n",
        "                    max_t=5,\n",
        "                    )\n",
        "\n",
        "                rt = res['rts'][0][0]\n",
        "                action = res['choices'][0][0]\n",
        "\n",
        "\n",
        "                reward = step_action(state, action, S_R_map)\n",
        "                #print(\"\\t\\t\\tdone action\", state, action, reward)\n",
        "\n",
        "                #print(\"\\t\\t\\tupdating q\")\n",
        "                if reward == 1:\n",
        "                    sub_list_corr.append(1)\n",
        "                    q_RL[state, action] = q_RL[state, action] + alpha * (reward - q_RL[state, action])\n",
        "                    q_WM[state, action] = reward\n",
        "                elif reward == 0:\n",
        "                    sub_list_corr.append(0)\n",
        "                    q_RL[state, action] = q_RL[state, action] + gamma * alpha * (reward - q_RL[state, action])\n",
        "                    q_WM[state, action] = q_WM[state, action] + gamma * (reward - q_WM[state, action])\n",
        "                #print(\"\\t\\t\\tdone updating q\")\n",
        "                q_WM = q_WM + phi * ((1/num_actions)-q_WM)\n",
        "                #print(\"\\t\\t\\tdone WM decay\")\n",
        "\n",
        "                # store data\n",
        "                sub_list_sub_id.append(subj)\n",
        "                sub_list_block_num.append(bl)\n",
        "                sub_list_stim.append(state)\n",
        "                sub_list_actions.append(action)\n",
        "                sub_list_reward.append(reward)\n",
        "                sub_list_stim_ctr.append(stim_counter[state])\n",
        "                sub_list_set_size.append(set_size)\n",
        "                sub_list_rt.append(rt)\n",
        "        #     print(\"\\t\\t -- end trial\")\n",
        "        # print(\"\\t -- end block\")\n",
        "\n",
        "    sub_list_sub_id = np.array(sub_list_sub_id)\n",
        "    sub_list_stim = np.array(sub_list_stim)\n",
        "    sub_list_actions = np.array(sub_list_actions)\n",
        "    sub_list_reward = np.array(sub_list_reward)\n",
        "    sub_list_block_num = np.array(sub_list_block_num)\n",
        "    sub_list_corr = np.array(sub_list_corr)\n",
        "    sub_list_stim_ctr = np.array(sub_list_stim_ctr)\n",
        "    sub_list_rt = np.array(sub_list_rt)\n",
        "\n",
        "\n",
        "    sub_data = np.stack([sub_list_sub_id, sub_list_block_num, sub_list_stim, sub_list_actions, sub_list_reward, sub_list_corr, sub_list_stim_ctr, sub_list_set_size, sub_list_rt], axis=1)\n",
        "    data = pd.DataFrame(sub_data, columns=['subj_idx', 'block_num', 'stim', 'response', 'feedback', 'corr', 'stim_ctr', 'set_size', 'rt'])\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "NjLJGmcJblqC",
        "outputId": "c6d1a3d5-8862-444e-a7a7-67829cc69c2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 3, 2, 4, 6, 5, 2, 3, 3, 1, 5, 2, 3, 5, 2, 1, 1, 6, 4, 4, 3, 6]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "s_size = [1, 2, 3, 4, 5, 6]\n",
        "freq = [3, 4, 6, 3, 3, 3]\n",
        "\n",
        "set_size_list = []\n",
        "for i in range(len(s_size)):\n",
        "    set_size_list.extend([s_size[i]]*freq[i])\n",
        "\n",
        "np.random.shuffle(set_size_list)\n",
        "set_size_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "y9Q0dhfdblqC"
      },
      "outputs": [],
      "source": [
        "num_rep_per_block = [15]\n",
        "\n",
        "num_datasets = 1\n",
        "num_actions = 3\n",
        "subjs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "5HSpkGqdblqC"
      },
      "outputs": [],
      "source": [
        "priors_a = [0.6, 0.7]\n",
        "priors_z = [0.2, 0.3]\n",
        "priors_theta = [0.05, 0.15]\n",
        "priors_rl_alpha = [0.002, 0.008]\n",
        "priors_rl_phi = [0.30, 0.40]\n",
        "priors_rl_rho = [0.65, 0.75]\n",
        "priors_rl_gamma = [0.60, 0.90]\n",
        "priors_rl_epsilon = [0, 0.05]\n",
        "priors_rl_C = [2.5, 4]\n",
        "\n",
        "rl_a = np.random.uniform(priors_a[0], priors_a[1], subjs)\n",
        "rl_z = np.random.uniform(priors_z[0], priors_z[1], subjs)\n",
        "rl_theta = np.random.uniform(priors_theta[0], priors_theta[1], subjs)\n",
        "rl_alpha = np.random.uniform(priors_rl_alpha[0], priors_rl_alpha[1], subjs)\n",
        "rl_phi = np.random.uniform(priors_rl_phi[0], priors_rl_phi[1], subjs)\n",
        "rl_rho = np.random.uniform(priors_rl_rho[0], priors_rl_rho[1], subjs)\n",
        "rl_gamma = np.random.uniform(priors_rl_gamma[0], priors_rl_gamma[1], subjs)\n",
        "rl_epsilon = np.random.uniform(priors_rl_epsilon[0], priors_rl_epsilon[1], subjs)\n",
        "rl_C = np.random.uniform(priors_rl_C[0], priors_rl_C[1], subjs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "IDsg1-5eEfmz"
      },
      "outputs": [],
      "source": [
        "# specify the fixed parameters and optimization settings\n",
        "\n",
        "model_rl = 'RLWM' # the model name (must be one of the keys in model_config_rl)\n",
        "num_actions = 3 # the number of actions in the RLWM task\n",
        "beta = 100 # the inverse temperature parameter in the softmax function\n",
        "\n",
        "n_restarts = 20 # the number of random restarts for each C value during the optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "tLVz1e7fblqC",
        "outputId": "5ac17de5-f486-4b00-a394-455de3ca6032",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==> dataset:  0\n",
            "[dataset: 0] generating subj data: 0\n",
            "\t -- [0.62029291 0.24674573 0.13159577 0.00310652 0.30043802 0.65976321\n",
            " 0.75079352 0.03134411 2.82169695]\n",
            "[dataset: 0] generating subj data: 1\n",
            "\t -- [0.64719265 0.24899288 0.09131297 0.00340071 0.39184863 0.67085836\n",
            " 0.61041428 0.03917995 3.27673272]\n",
            "[dataset: 0] generating subj data: 2\n",
            "\t -- [0.69489428 0.25848909 0.08008685 0.00330873 0.32128529 0.66159558\n",
            " 0.83513309 0.01726633 2.77723809]\n",
            "[dataset: 0] generating subj data: 3\n",
            "\t -- [0.60371222 0.287456   0.05379728 0.00673751 0.39233001 0.74104626\n",
            " 0.75066581 0.03558638 3.89349046]\n",
            "[dataset: 0] generating subj data: 4\n",
            "\t -- [0.62716999 0.27393564 0.09272666 0.0056989  0.31582679 0.73936429\n",
            " 0.62232058 0.02590137 2.72809848]\n",
            "[dataset: 0] generating subj data: 5\n",
            "\t -- [0.6222572  0.24395143 0.07245351 0.00700027 0.31659199 0.69759262\n",
            " 0.87950005 0.03739667 2.89393004]\n",
            "[dataset: 0] generating subj data: 6\n",
            "\t -- [6.79465382e-01 2.11305877e-01 1.21843728e-01 5.44634638e-03\n",
            " 3.41495634e-01 6.75749494e-01 7.29956234e-01 5.15157609e-06\n",
            " 2.72109211e+00]\n",
            "[dataset: 0] generating subj data: 7\n",
            "\t -- [6.61462735e-01 2.90251024e-01 7.75408905e-02 3.22284929e-03\n",
            " 3.98229336e-01 7.34319538e-01 7.40246414e-01 3.63385080e-02\n",
            " 3.76749466e+00]\n",
            "[dataset: 0] generating subj data: 8\n",
            "\t -- [0.63786162 0.22153907 0.1171974  0.00355438 0.37045715 0.67825511\n",
            " 0.79452174 0.00540912 3.45193354]\n",
            "[dataset: 0] generating subj data: 9\n",
            "\t -- [0.65577267 0.21696866 0.145067   0.00657792 0.38569687 0.70679564\n",
            " 0.76520818 0.00571627 2.65226482]\n",
            "[dataset: 0] generating subj data: 10\n",
            "\t -- [0.6971629  0.21348928 0.09927361 0.00510347 0.36010824 0.7186601\n",
            " 0.83687057 0.03481034 3.62005331]\n",
            "[dataset: 0] generating subj data: 11\n",
            "\t -- [0.67647021 0.24575949 0.11690195 0.00788422 0.3979265  0.68319374\n",
            " 0.8186848  0.01911385 3.80367557]\n",
            "[dataset: 0] generating subj data: 12\n",
            "\t -- [6.68368059e-01 2.04315675e-01 1.25452363e-01 2.77633595e-03\n",
            " 3.91719140e-01 7.39120923e-01 8.26112396e-01 1.97819343e-02\n",
            " 3.34721609e+00]\n",
            "[dataset: 0] generating subj data: 13\n",
            "\t -- [0.68465454 0.22231711 0.08276445 0.00676623 0.3329631  0.70752747\n",
            " 0.61171131 0.01966894 3.07134544]\n",
            "[dataset: 0] generating subj data: 14\n",
            "\t -- [0.69673322 0.245679   0.09416491 0.00686991 0.34503097 0.66748937\n",
            " 0.62653223 0.04280155 2.71891299]\n",
            "[dataset: 0] generating subj data: 15\n",
            "\t -- [6.94286517e-01 2.18684640e-01 9.86662436e-02 2.10858728e-03\n",
            " 3.17442844e-01 6.66545898e-01 7.84139051e-01 6.37444651e-03\n",
            " 3.58591685e+00]\n",
            "[dataset: 0] generating subj data: 16\n",
            "\t -- [6.50750482e-01 2.72411061e-01 1.13673008e-01 3.02278272e-03\n",
            " 3.70217109e-01 7.00576617e-01 7.86551882e-01 9.00494701e-03\n",
            " 3.80567152e+00]\n",
            "[dataset: 0] generating subj data: 17\n",
            "\t -- [0.67283774 0.27118817 0.08180435 0.00358692 0.32307163 0.69323654\n",
            " 0.8998996  0.02348835 2.57174391]\n",
            "[dataset: 0] generating subj data: 18\n",
            "\t -- [0.65887171 0.22904761 0.067442   0.00341203 0.35538912 0.73517385\n",
            " 0.69842282 0.04336276 2.87446433]\n",
            "[dataset: 0] generating subj data: 19\n",
            "\t -- [0.67085643 0.27298898 0.08712929 0.00674003 0.33331318 0.72280603\n",
            " 0.61706069 0.02672873 3.01010571]\n"
          ]
        }
      ],
      "source": [
        "file = list()\n",
        "\n",
        "for n in range(num_datasets):\n",
        "    print(\"\\n==> dataset: \", n)\n",
        "    dataset_file = {}\n",
        "\n",
        "    dataset_file['info'] = {\n",
        "                        'num_datasets': num_datasets, 'num_subj': subjs, 'num_actions': num_actions,\n",
        "                        'model_rl': model_rl,\n",
        "                        'set_size_list': set_size_list, 'num_rep_per_block': num_rep_per_block\n",
        "                        }\n",
        "\n",
        "    dataset_file['data'] = list()\n",
        "    for i in range(subjs):\n",
        "        print(\"[dataset: %d] generating subj data: %d\" % (n, i))\n",
        "\n",
        "        subj_param_rl = np.array([rl_a[i], rl_z[i], rl_theta[i], rl_alpha[i], rl_phi[i], rl_rho[i], rl_gamma[i], rl_epsilon[i], rl_C[i]])\n",
        "        print(\"\\t --\", subj_param_rl)\n",
        "\n",
        "        subj_data = {}\n",
        "\n",
        "        sim_data = simulate_RLWM(subj_param_rl, set_size_list, num_rep_per_block, num_actions=num_actions, subjs=1)\n",
        "        sim_data['subj_idx'] = i\n",
        "\n",
        "        subj_data['subj_idx'] = i\n",
        "        subj_data['true_param'] = subj_param_rl\n",
        "        subj_data['sim_data'] = sim_data\n",
        "\n",
        "        #print(\"\\t --\", subj_param_rl, subj_data['true_param'])\n",
        "        dataset_file['data'].append(subj_data)\n",
        "\n",
        "    file.append(dataset_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "t6N8EmRxblqC"
      },
      "outputs": [],
      "source": [
        "# before saving; check data using data validation code below\n",
        "# save first dataset in the datafile\n",
        "dataset_file = file[0]\n",
        "\n",
        "param_list = ['true_a', 'true_z', 'true_theta', 'true_alpha', 'true_phi', 'true_rho', 'true_gamma', 'true_epsilon', 'true_C']\n",
        "\n",
        "list_sub_data = list()\n",
        "for itr in range(len(dataset_file['data'])):\n",
        "    data = dataset_file['data'][itr]['sim_data']\n",
        "\n",
        "    for p, p_name in zip(dataset_file['data'][itr]['true_param'], param_list):\n",
        "        data[p_name] = p\n",
        "\n",
        "    data['subj_idx'] = itr\n",
        "\n",
        "    list_sub_data.append(data)\n",
        "PR_data = pd.concat(list_sub_data, ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyMC"
      ],
      "metadata": {
        "id": "4_BF9HdxeeJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Prepare data for PyTensor"
      ],
      "metadata": {
        "id": "kn55XiSTeh9B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "fss6e6hQ8Elv"
      },
      "outputs": [],
      "source": [
        "df = PR_data.sort_values(['subj_idx', 'block_num'])\n",
        "df = df.loc[df['subj_idx'].isin([0])]\n",
        "# df = df.loc[df['block_num'].isin(['0.0','1.0','2.0'])]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PR_data"
      ],
      "metadata": {
        "id": "HUm4lPdQeeVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npPzhBVYUwAU",
        "outputId": "6fd9953f-b7c0-4a9a-a44d-229a18767036"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35640, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ],
      "source": [
        "max_trials = df[['subj_idx','block_num']].value_counts().max()\n",
        "max_stimuli = int(df['stim'].max()) + 1\n",
        "n_participants = len(df['subj_idx'].unique())\n",
        "n_choices = int(df['response'].max()) + 1\n",
        "n_blocks = len(df['block_num'].unique())\n",
        "\n",
        "\n",
        "shape = (n_participants, n_blocks, max_trials, n_choices, max_stimuli)\n",
        "pad_value = 0\n",
        "# stimuli = np.ones(shape) * -100\n",
        "stim_choices = np.ones(shape) * pad_value\n",
        "rewards = np.ones(shape) * pad_value\n",
        "rts = np.ones(shape) * pad_value\n",
        "set_sizes = np.repeat(np.array(df.groupby(['subj_idx','block_num']).mean()['set_size']),repeats=max_trials*n_choices*max_stimuli).flatten()\n",
        "subj_idxs = np.repeat(np.arange(n_participants),max_trials*n_choices*n_blocks*max_stimuli).flatten()\n",
        "block_nums = np.tile(np.repeat(np.arange(n_blocks), repeats=max_trials*n_choices*max_stimuli),n_participants).flatten()\n",
        "\n",
        "for i, subj_idx in enumerate(df['subj_idx'].unique()):\n",
        "    for j, block_num in enumerate(df['block_num'].unique()):\n",
        "\n",
        "        subj_block_data = df[(df['subj_idx'] == subj_idx) & (df['block_num'] == block_num)]\n",
        "        n_trials = subj_block_data.shape[0]\n",
        "        subj_block_stimuli = subj_block_data['stim'].to_numpy(dtype=np.int32)\n",
        "        n_stimuli = subj_block_stimuli.max() + 1\n",
        "        subj_block_choices = subj_block_data['response'].to_numpy(dtype=np.int32)\n",
        "        subj_block_rewards = subj_block_data['feedback'].to_numpy(dtype=np.float32)\n",
        "        subj_block_rts = subj_block_data['rt'].to_numpy(dtype=np.float32)\n",
        "\n",
        "        subj_stimuli_stim_choices = np.stack([subj_block_stimuli, subj_block_choices], axis=-1)\n",
        "\n",
        "        onehot_stim_choices = np.zeros((n_trials, n_choices, n_stimuli))\n",
        "        for t in range(n_trials):\n",
        "            stim = subj_block_stimuli[t]\n",
        "            choice = subj_block_choices[t]\n",
        "            onehot_stim_choices[t,choice,stim] = 1\n",
        "\n",
        "        # subj_stimuli_stim_choices = np.eye([n_choices, max_stimuli])[subj_stimuli_stim_choices]\n",
        "        #subj_block_stimuli = np.eye(max_stimuli)[subj_block_stimuli]\n",
        "        #subj_block_choices = np.eye((n_choices, max_stimuli))[subj_block_choices]\n",
        "        subj_block_rewards = subj_block_rewards.reshape((n_trials, 1, 1)).repeat(n_choices, axis=1).repeat(n_stimuli, axis=2)\n",
        "        subj_block_rts = subj_block_rts.reshape((n_trials, 1, 1)).repeat(n_choices, axis=1).repeat(n_stimuli, axis=2)\n",
        "\n",
        "        # stimuli[subj_idx, int(block_num), :n_trials, :, :] = subj_block_stimuli\n",
        "        stim_choices[i, j, :n_trials, :, :n_stimuli] = onehot_stim_choices\n",
        "        rewards[i, j, :n_trials, :, :n_stimuli] = subj_block_rewards\n",
        "        rts[i, j, :n_trials, :, :n_stimuli] = subj_block_rts\n",
        "\n",
        "\n",
        "\n",
        "padded_ohe_df = pd.DataFrame(data={'subj_idx': subj_idxs,\n",
        "                               'block_num': block_nums,\n",
        "                               'response': stim_choices.flatten(),\n",
        "                               'feedback': rewards.flatten(),\n",
        "                               'rt': rts.flatten(),\n",
        "                               'set_size': set_sizes,\n",
        "                               })\n",
        "padded_ohe_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###PyMC Wrapper and Compile"
      ],
      "metadata": {
        "id": "4isrnx5_e4qP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "EH_fwWmv5pen"
      },
      "outputs": [],
      "source": [
        "n_trials, n_participants, n_choices, n_blocks, max_stimuli = (max_trials, n_participants, n_choices, n_blocks, max_stimuli)\n",
        "\n",
        "def rlwmssm_hdll(pA_, pB_, pC_, pE_, pG_, pP_, pR_, choices, rewards, set_sizes_, pssmA_, pssmZ_, pssmT_, df_choices_, df_rts_, weights_0__,weights_1__,weights_2__,weights_3__,biases_0__,biases_1__,biases_2__,biases_3__):\n",
        "    inner_shape = (n_participants, n_choices, n_blocks, max_stimuli)\n",
        "    full_shape = (inner_shape[0], inner_shape[2], n_trials, inner_shape[1], inner_shape[3])\n",
        "    dq_RL_ = pt.ones(inner_shape) / n_choices\n",
        "    dq_WM_ = pt.ones(inner_shape) / n_choices\n",
        "\n",
        "    dC_ = choices.reshape(full_shape).dimshuffle((2,0,3,1,4))\n",
        "    dR_ = rewards.reshape(full_shape).dimshuffle((2,0,3,1,4))\n",
        "    set_sizes_ = set_sizes_.reshape(full_shape).dimshuffle((2,0,3,1,4))\n",
        "\n",
        "    pA_ = pA_.reshape(full_shape).dimshuffle((2,0,3,1,4))\n",
        "    pB_ = pB_.reshape(full_shape).dimshuffle((2,0,3,1,4))\n",
        "    pC_ = pC_.reshape(full_shape).dimshuffle((2,0,3,1,4))\n",
        "    pE_ = pE_.reshape(full_shape).dimshuffle((2,0,3,1,4))\n",
        "    pG_ = pG_.reshape(full_shape).dimshuffle((2,0,3,1,4))\n",
        "    pP_ = pP_.reshape(full_shape).dimshuffle((2,0,3,1,4))\n",
        "    pR_ = pR_.reshape(full_shape).dimshuffle((2,0,3,1,4))\n",
        "\n",
        "    return rlwmssm_recovery(dq_RL_, dq_WM_, dC_, dR_, pA_, pB_, pC_, pE_, pG_, pP_, pR_, set_sizes_, pssmA_, pssmZ_, pssmT_, df_choices_, df_rts_, weights_0__,weights_1__,weights_2__,weights_3__,biases_0__,biases_1__,biases_2__,biases_3__).flatten()\n",
        "    #return rlwmssm_Ps(dq_RL_, dq_WM_, dC_, dR_, pA_, pB_, pG_, pP_)\n",
        "    #return rlwm_scan(dC_, dR_, pA_, pG_, pP_, dq_RL_, dq_WM_)\n",
        "\n",
        "pA = pt.dvector()\n",
        "pB = pt.dvector()\n",
        "pC = pt.dvector()\n",
        "pE = pt.dvector()\n",
        "pG = pt.dvector()\n",
        "pP = pt.dvector()\n",
        "pR = pt.dvector()\n",
        "choices__ = pt.dvector()\n",
        "rewards__ = pt.dvector()\n",
        "set_sizes__ = pt.dvector()\n",
        "df_choices__ = pt.dvector()\n",
        "df_rts__ = pt.dvector()\n",
        "pssmA__ = pt.dvector()\n",
        "pssmZ__ = pt.dvector()\n",
        "pssmT__ = pt.dvector()\n",
        "weights_0__ = pt.dmatrix()\n",
        "weights_1__ = pt.dmatrix()\n",
        "weights_2__ = pt.dmatrix()\n",
        "weights_3__ = pt.dmatrix()\n",
        "biases_0__ = pt.dvector()\n",
        "biases_1__ = pt.dvector()\n",
        "biases_2__ = pt.dvector()\n",
        "biases_3__ = pt.dvector()\n",
        "\n",
        "output = rlwmssm_hdll(pA, pB, pC, pE, pG, pP, pR, choices__, rewards__, set_sizes__, pssmA__, pssmZ__, pssmT__, df_choices__,df_rts__, weights_0__,weights_1__,weights_2__,weights_3__,biases_0__,biases_1__,biases_2__,biases_3__)\n",
        "\n",
        "my_rlwmssm_hdll_func = pytensor.function(inputs=[pA, pB, pC, pE, pG, pP, pR, choices__, rewards__, set_sizes__, df_choices__, df_rts__, pssmA__, pssmZ__, pssmT__, weights_0__,weights_1__,weights_2__,weights_3__,biases_0__,biases_1__,biases_2__, biases_3__], outputs=output, on_unused_input='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "lkxHdL8qBBL3"
      },
      "outputs": [],
      "source": [
        "pA_ = np.ones(padded_ohe_df.shape[0]).flatten() * rl_alpha[0]\n",
        "pB_ = np.ones(padded_ohe_df.shape[0]).flatten() * 100\n",
        "pC_ = np.ones(padded_ohe_df.shape[0]).flatten() * rl_C[0]\n",
        "pE_ = np.ones(padded_ohe_df.shape[0]).flatten() * rl_epsilon[0]\n",
        "pG_ = np.ones(padded_ohe_df.shape[0]).flatten() * rl_gamma[0]\n",
        "pP_ = np.ones(padded_ohe_df.shape[0]).flatten() * rl_phi[0]\n",
        "pR_ = np.ones(padded_ohe_df.shape[0]).flatten() * rl_rho[0]\n",
        "pssmA_ = np.ones(padded_ohe_df.shape[0]//n_choices).flatten() * rl_a[0]\n",
        "pssmZ_ = np.ones(padded_ohe_df.shape[0]//n_choices).flatten() * rl_z[0]\n",
        "pssmT_ = np.ones(padded_ohe_df.shape[0]//n_choices).flatten() * rl_theta[0]\n",
        "choices_ = padded_ohe_df['response'].to_numpy(dtype=np.int32)\n",
        "rewards_ = padded_ohe_df['feedback'].to_numpy(dtype=np.float32)\n",
        "set_sizes_ = padded_ohe_df['set_size'].to_numpy(dtype=np.float32)\n",
        "df_choices_ = df['response']\n",
        "df_rts_ = df['rt']\n",
        "weights_0_ = weights_0\n",
        "weights_1_ = weights_1\n",
        "weights_2_ = weights_2\n",
        "weights_3_ = weights_3\n",
        "biases_0_ = biases_0\n",
        "biases_1_ = biases_1\n",
        "biases_2_ = biases_2\n",
        "biases_3_ = biases_3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W61ntXxxpeJl",
        "outputId": "69f61b02-1f27-49b2-9e9f-782f92345f13"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1110, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###PyTensor Python Comparison"
      ],
      "metadata": {
        "id": "tMMAdYOHe7T7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 929
        },
        "id": "KhENkdWjMhhc",
        "outputId": "53063d01-b788-4719-8957-e5f41bffe58e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 11880 and the array at index 2 has size 1110\nApply node that caused the error: Join(1, Reshape{2}.0, ExpandDims{axis=1}.0, ExpandDims{axis=1}.0, ExpandDims{axis=1}.0, ExpandDims{axis=1}.0, ExpandDims{axis=1}.0)\nToposort index: 74\nInputs types: [TensorType(int8, shape=()), TensorType(float64, shape=(None, 3)), TensorType(float64, shape=(None, 1)), TensorType(float64, shape=(None, 1)), TensorType(float64, shape=(None, 1)), TensorType(float64, shape=(None, 1)), TensorType(float64, shape=(None, 1))]\nInputs shapes: [(), (11880, 3), (11880, 1), (1110, 1), (1110, 1), (11880, 1), (11880, 1)]\nInputs strides: [(), (24, 8), (8, 8), (8, 8), (8, 8), (8, 8), (8, 8)]\nInputs values: [array(1, dtype=int8), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown']\nOutputs clients: [[Dot22(Join.0, <Matrix(float64, shape=(?, ?))>)]]\n\nBacktrace when the node is created (use PyTensor flag traceback__limit=N to make it longer):\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-155-f23fddf28cff>\", line 49, in <cell line: 49>\n    output = rlwmssm_hdll(pA, pB, pC, pE, pG, pP, pR, choices__, rewards__, set_sizes__, pssmA__, pssmZ__, pssmT__, df_choices__,df_rts__, weights_0__,weights_1__,weights_2__,weights_3__,biases_0__,biases_1__,biases_2__,biases_3__)\n  File \"<ipython-input-155-f23fddf28cff>\", line 21, in rlwmssm_hdll\n    return rlwmssm_recovery(dq_RL_, dq_WM_, dC_, dR_, pA_, pB_, pC_, pE_, pG_, pP_, pR_, set_sizes_, pssmA_, pssmZ_, pssmT_, df_choices_, df_rts_, weights_0__,weights_1__,weights_2__,weights_3__,biases_0__,biases_1__,biases_2__,biases_3__).flatten()\n  File \"<ipython-input-149-2f3b90fa90ad>\", line 112, in rlwmssm_recovery\n    likelihood = rlwmssm_likelihood(dC, dq_RL, dq_WM, pB, pC, pE, pR, set_sizes, pssmA, pssmZ, pssmT, dssmC, dssmRT, weights_0,weights_1,weights_2,weights_3,biases_0,biases_1,biases_2,biases_3)\n  File \"<ipython-input-149-2f3b90fa90ad>\", line 93, in rlwmssm_likelihood\n    in_ = pt.concatenate([pssmV, pssmA.reshape((-1,1)), pssmZ.reshape((-1,1)), pssmT.reshape((-1,1)), dssmRT.reshape((-1,1)), dssmC.reshape((-1,1))], axis=1)\n\nHINT: Use the PyTensor flag `exception_verbosity=high` for a debug print-out and storage map footprint of this Apply node.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytensor/compile/function/types.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    969\u001b[0m             outputs = (\n\u001b[0;32m--> 970\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 11880 and the array at index 2 has size 1110",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-157-feec5c328ea8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#my_rlwm_hdll_func(pA_, pB_, pC_, pE_, pG_, pP_, pR_, choices_, rewards_, set_sizes_).sum()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmy_rlwmssm_hdll_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpA_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpB_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpC_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpE_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpG_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpP_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpR_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchoices_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_sizes_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpssmA_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpssmZ_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpssmT_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_choices_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_rts_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_0_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights_1_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights_2_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights_3_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbiases_0_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbiases_1_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbiases_2_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbiases_3_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytensor/compile/function/types.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"thunks\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m                     \u001b[0mthunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m                 raise_with_op(\n\u001b[0m\u001b[1;32m    984\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytensor/link/utils.py\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(fgraph, node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;31m# Some exception need extra parameter in inputs. So forget the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;31m# extra long error message in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytensor/compile/function/types.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m             outputs = (\n\u001b[0;32m--> 970\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 11880 and the array at index 2 has size 1110\nApply node that caused the error: Join(1, Reshape{2}.0, ExpandDims{axis=1}.0, ExpandDims{axis=1}.0, ExpandDims{axis=1}.0, ExpandDims{axis=1}.0, ExpandDims{axis=1}.0)\nToposort index: 74\nInputs types: [TensorType(int8, shape=()), TensorType(float64, shape=(None, 3)), TensorType(float64, shape=(None, 1)), TensorType(float64, shape=(None, 1)), TensorType(float64, shape=(None, 1)), TensorType(float64, shape=(None, 1)), TensorType(float64, shape=(None, 1))]\nInputs shapes: [(), (11880, 3), (11880, 1), (1110, 1), (1110, 1), (11880, 1), (11880, 1)]\nInputs strides: [(), (24, 8), (8, 8), (8, 8), (8, 8), (8, 8), (8, 8)]\nInputs values: [array(1, dtype=int8), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown']\nOutputs clients: [[Dot22(Join.0, <Matrix(float64, shape=(?, ?))>)]]\n\nBacktrace when the node is created (use PyTensor flag traceback__limit=N to make it longer):\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-155-f23fddf28cff>\", line 49, in <cell line: 49>\n    output = rlwmssm_hdll(pA, pB, pC, pE, pG, pP, pR, choices__, rewards__, set_sizes__, pssmA__, pssmZ__, pssmT__, df_choices__,df_rts__, weights_0__,weights_1__,weights_2__,weights_3__,biases_0__,biases_1__,biases_2__,biases_3__)\n  File \"<ipython-input-155-f23fddf28cff>\", line 21, in rlwmssm_hdll\n    return rlwmssm_recovery(dq_RL_, dq_WM_, dC_, dR_, pA_, pB_, pC_, pE_, pG_, pP_, pR_, set_sizes_, pssmA_, pssmZ_, pssmT_, df_choices_, df_rts_, weights_0__,weights_1__,weights_2__,weights_3__,biases_0__,biases_1__,biases_2__,biases_3__).flatten()\n  File \"<ipython-input-149-2f3b90fa90ad>\", line 112, in rlwmssm_recovery\n    likelihood = rlwmssm_likelihood(dC, dq_RL, dq_WM, pB, pC, pE, pR, set_sizes, pssmA, pssmZ, pssmT, dssmC, dssmRT, weights_0,weights_1,weights_2,weights_3,biases_0,biases_1,biases_2,biases_3)\n  File \"<ipython-input-149-2f3b90fa90ad>\", line 93, in rlwmssm_likelihood\n    in_ = pt.concatenate([pssmV, pssmA.reshape((-1,1)), pssmZ.reshape((-1,1)), pssmT.reshape((-1,1)), dssmRT.reshape((-1,1)), dssmC.reshape((-1,1))], axis=1)\n\nHINT: Use the PyTensor flag `exception_verbosity=high` for a debug print-out and storage map footprint of this Apply node."
          ]
        }
      ],
      "source": [
        "#my_rlwm_hdll_func(pA_, pB_, pC_, pE_, pG_, pP_, pR_, choices_, rewards_, set_sizes_).sum()\n",
        "my_rlwmssm_hdll_func(pA_, pB_, pC_, pE_, pG_, pP_, pR_, choices_, rewards_, set_sizes_, pssmA_, pssmZ_, pssmT_, df_choices_, df_rts_, weights_0_,weights_1_,weights_2_,weights_3_,biases_0_,biases_1_,biases_2_,biases_3_).sum()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1110*6*2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5iebgMdpxEI",
        "outputId": "47db324e-14ad-4f04-fb1a-29cff8878baa"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13320"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Upy4HSBmqjSV",
        "outputId": "6014bc81-8ff2-484c-c6ad-e5f035239666"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-825.9748122896546"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ],
      "source": [
        "ll = 0\n",
        "for subj_idx in df['subj_idx'].unique():\n",
        "  ll += RLWM_LL((pA_[0], pP_[0], pR_[0], pG_[0], pE_[0]), df.loc[df['subj_idx']==subj_idx], 3, pC_[0], pB_[0])\n",
        "# ll, Qs = RLWM_LL((pA_[0], pP_[0], pR_[0], pG_[0], pE_[0]), df, 3, pC_[0], pB_[0])\n",
        "ll"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Run PyMC"
      ],
      "metadata": {
        "id": "pejPRWusfubr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "4deb8c856a4c444db3a91a8237293267",
            "e469368595fc480f8eb03d53713eba47",
            "a4fd62750b61486c99c25c7adeabbe06",
            "0530f83c731a46c8ac7386475f79d38d",
            "d2676737ec9244f9b742cd8b572e9011",
            "8d685fc29fdc42b3a65f223bb18d8555",
            "d5e49545e0ca4729b767e741e2e2b817",
            "a30139d5583a42888be334adb254c1e2",
            "9fb7da58202f4f3991a81cc595d17bfb",
            "af3018095f5f40348a50a05f9ab4136f",
            "050d5d274e4a4580b67e38fdb40b4155",
            "5b518233732b44379fe5285ef6d66f44",
            "3b8041164e074fcd884c49b777828d5a",
            "7c2a9aab0347404a9de051c7c4bb3b65",
            "dcb329882d8142e6bc33da393083454c",
            "81418e8900c84ac9bb9cef49e10f5b88",
            "9dd7660aaed24b1086421f59b6089230",
            "5c5e0d44f88443848ab724a2786ac765",
            "6f9010b001dc47c9b78a1fdb93489f50",
            "d006819af7c0400ebfb0289b3012cabe",
            "e051fee817104031b8333898d6349a12",
            "fdda78dc3259483f993349e284c0b6ea",
            "0e012e3ca58d43038fff96ed2e0bdcbd",
            "e7ea6c2ffb67421fb4260e4d8c39554c",
            "fe166430f39b42af8c009cb846995a32",
            "345b4134cb10431db5542bff84017fbf",
            "c27104a50bab459a8b0252799607c8aa",
            "baae53156838460a8f0b7bc5f5a82963",
            "e1ba5a4a0c1b43d58c1d42468e8164e7",
            "abd051d4a81046e4a2e6acfd6d917e3b",
            "6d01e552ea824399aa8f8768bc904107",
            "e451e1b75f1a4fa78970a6343552b6f4",
            "7db57ced51dc49e88c6ba3af8766c439",
            "3f37cdbf720e4abfbe6558411d675f2f",
            "ded87cbd0bf14fb38a6e874c56bae6c4",
            "2059bd34141c43f9b14d9ced2af6199a",
            "84e0a647eb554186943bd0832eeabb4e",
            "2202a79596264411a2cffb3788f2ddaf",
            "9d4254de03fa4ef6bc180c4651e513d6",
            "41843d4f914c47f7acd3e47e3089f84e",
            "cb81f6fbc55a4bffbff2e5039c9c257a",
            "8b67a71e77de435e958176489a1d6333",
            "62e0c967038044b78afba6c487f93e04",
            "5e82c682265a46a3838ccad633eaf87e"
          ]
        },
        "id": "X-7hleDBp4QG",
        "outputId": "d98a91dd-9223-4699-ad26-e9584831517a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pymc.sampling.mcmc:Only 10 samples in chain.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4deb8c856a4c444db3a91a8237293267"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b518233732b44379fe5285ef6d66f44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e012e3ca58d43038fff96ed2e0bdcbd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f37cdbf720e4abfbe6558411d675f2f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Make coordinates\n",
        "participant_ids, participants = pd.factorize(padded_ohe_df['subj_idx'])\n",
        "coords = {\n",
        "          \"participant_idx\": np.array(participants),\n",
        "          \"obs_idx\": np.arange(padded_ohe_df.shape[0])\n",
        "         }\n",
        "\n",
        "with pm.Model(coords=coords) as hierarchical_model:\n",
        "    # Data\n",
        "    #Choices = pm.ConstantData('Choices', padded_ohe_df['response'].to_numpy())\n",
        "    #Rewards = pm.ConstantData('Rewards', padded_ohe_df['feedback'].to_numpy())\n",
        "    #Set_sizes = pm.ConstantData('Set_sizes', padded_ohe_df['set_size'].to_numpy())\n",
        "    Choices = pm.ConstantData('Choices', choices_)\n",
        "    Rewards = pm.ConstantData('Rewards', rewards_)\n",
        "    Set_sizes = pm.ConstantData('Set_sizes', set_sizes_)\n",
        "\n",
        "\n",
        "\n",
        "    # Hyperpriors for group nodes\n",
        "    # pA_alpha = 3 # pm.Gamma(\"pA_alpha\", alpha = 3. , beta = 3.)\n",
        "    # pA_beta = 3 # pm.Gamma(\"pA_beta\", alpha = 3. , beta = 3.)\n",
        "    # # pB_alpha = 3 # pm.Gamma(\"pB_alpha\", alpha = 3. , beta = 3.)\n",
        "    # # pB_beta = 3 # pm.Gamma(\"pB_beta\", alpha = 3. , beta = 3.)\n",
        "    # pC_alpha = 3 # pm.Gamma(\"pC_alpha\", alpha = 3. , beta = 3.)\n",
        "    # pC_beta = 3 # pm.Gamma(\"pC_beta\", alpha = 3. , beta = 3.)\n",
        "    # pE_alpha = 3 # pm.Gamma(\"pE_alpha\", alpha = 3. , beta = 3.)\n",
        "    # pE_beta = 3 # pm.Gamma(\"pE_beta\", alpha = 3. , beta = 3.)\n",
        "    # pG_alpha = 3 # pm.Gamma(\"pG_alpha\", alpha = 3. , beta = 3.)\n",
        "    # pG_beta = 3 # pm.Gamma(\"pG_beta\", alpha = 3. , beta = 3.)\n",
        "    # pP_alpha = 3 # pm.Gamma(\"pP_alpha\", alpha = 3. , beta = 3.)\n",
        "    # pP_beta = 3 # pm.Gamma(\"pP_beta\", alpha = 3. , beta = 3.)\n",
        "    # pR_alpha = 3 # pm.Gamma(\"pR_alpha\", alpha = 3. , beta = 3.)\n",
        "    # pR_beta = 3 # pm.Gamma(\"pR_beta\", alpha = 3. , beta = 3.)\n",
        "\n",
        "    # priors_rl_alpha = [0,0.01] # [0, 0.01]\n",
        "    # priors_rl_phi = [0.30,0.30]# [0, 0.40]\n",
        "    # priors_rl_rho = [0.8,0.8] # [0.75, 1]\n",
        "    # priors_rl_gamma =[0.7,0.7] # [0.60, 0.90]\n",
        "    # priors_rl_epsilon = [0.01,0.01] # [0, 0.05]\n",
        "    # priors_rl_C = [3,3] # [2, 5]\n",
        "\n",
        "\n",
        "    # Priors for variables\n",
        "    # pA = pm.ConstantData('pA', np.ones_like(choices_) * rl_alpha[0])\n",
        "    pB = pm.ConstantData('pB', np.ones_like(choices_) * 100.0)\n",
        "    # pC = pm.ConstantData('pC', np.ones_like(choices_) * rl_C[0])\n",
        "    # pE = pm.ConstantData('pE', np.ones_like(choices_) * rl_epsilon[0])\n",
        "    # pG = pm.ConstantData('pG', np.ones_like(choices) * rl_gamma[0])\n",
        "    # pP = pm.ConstantData('pP', np.ones_like(choices_) * rl_phi[0])\n",
        "    # pR = pm.ConstantData('pR', np.ones_like(choices_) * rl_rho[0])\n",
        "    pA = pm.Beta(name='pA', alpha=2.0, beta=100, dims=\"participant_idx\")#, initval=np.array(pA_[0]).reshape((-1,)))\n",
        "    # pB = pm.Uniform(name=\"pB\", lower=0.8, upper=1.2, dims=\"participant_idx\")\n",
        "    pC = pm.TruncatedNormal(name=\"pC\", mu=3.0, sigma=0.25, lower=2.0, upper=5.0, dims=\"participant_idx\")#, initval=np.array(pC_[0]).reshape((-1,)))\n",
        "    pE = pm.TruncatedNormal(name=\"pE\", mu=0.01, sigma=0.001, lower=0.0, upper=1.0, dims=\"participant_idx\")\n",
        "    pG = pm.TruncatedNormal(name=\"pG\", mu=0.1, sigma=0.01, lower=0.0, upper=1.0, dims=\"participant_idx\")#, initval=np.array(pG_[0]).reshape((-1,)))\n",
        "    pP = pm.TruncatedNormal(name=\"pP\",  mu=0.3, sigma=0.025, lower=0.0, upper=1.0, dims=\"participant_idx\")#, initval=np.array(pP_[0]).reshape((-1,)))\n",
        "    pR = pm.TruncatedNormal(name=\"pR\",  mu=0.8, sigma=0.025, lower=0.0, upper=1.0, dims=\"participant_idx\")#, initval=np.array(pR_[0]).reshape((-1,)))\n",
        "    # pA = pm.Beta(name=\"pA\", alpha=pA_alpha, beta=pA_beta, dims=\"participant_idx\")\n",
        "    # pB = pm.Beta(name=\"pB\", alpha=pB_alpha, beta=pB_beta, dims=\"participant_idx\")\n",
        "    # pC = pm.Beta(name=\"pC\", alpha=pC_alpha, beta=pC_beta, dims=\"participant_idx\")\n",
        "    # pE = pm.Beta(name=\"pE\", alpha=pE_alpha, beta=pE_beta, dims=\"participant_idx\")\n",
        "    # pG = pm.Beta(name=\"pG\", alpha=pG_alpha, beta=pG_beta, dims=\"participant_idx\")\n",
        "    # pP = pm.Beta(name=\"pP\", alpha=pP_alpha, beta=pP_beta, dims=\"participant_idx\")\n",
        "    # pR = pm.Beta(name=\"pR\", alpha=pR_alpha, beta=pR_beta, dims=\"participant_idx\")\n",
        "\n",
        "\n",
        "    # Render parameters trial wise\n",
        "    pA_trial = pA[participant_ids]\n",
        "    # pB_trial = pB[participant_ids]\n",
        "    pC_trial = pC[participant_ids]\n",
        "    # pE_trial = pE[participant_ids]\n",
        "    pG_trial = pG[participant_ids]\n",
        "    pP_trial = pP[participant_ids]\n",
        "    pR_trial = pR[participant_ids]\n",
        "    # pA_trial = pA\n",
        "    pB_trial = pB\n",
        "    #pC_trial = pC\n",
        "    pE_trial = pE\n",
        "    # pG_trial = pG\n",
        "    #pP_trial = pP\n",
        "    #pR_trial = pR\n",
        "\n",
        "    # CHOOSE WHICH WRAPPER FUNCTION TO USE HERE\n",
        "    pm.Potential(\"log_likelihood\", rlwm_hdll(pA_trial,pB_trial,pC_trial,pE_trial,pG_trial,pP_trial,pR_trial,Choices,Rewards,Set_sizes))\n",
        "    idata_pooled = pm.sample(1000, tune=1000, chains=4, nuts_sampler=\"numpyro\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "az.plot_trace(idata_pooled, lines=[\n",
        "    (\"pA\", {}, rl_alpha),\n",
        "    (\"pC\", {}, rl_C),\n",
        "    (\"pE\", {}, rl_epsilon),\n",
        "    (\"pG\", {}, rl_gamma),\n",
        "    (\"pP\", {}, rl_phi),\n",
        "    (\"pR\", {}, rl_rho),\n",
        "])"
      ],
      "metadata": {
        "id": "OGv_OeLcf4tG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}