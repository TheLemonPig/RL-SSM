{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/TheLemonPig/RL-SSM/blob/main/RLWM_SSM_differentiable.ipynb",
      "authorship_tag": "ABX9TyPO1yBTI9/4vwo0qPPpinxH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheLemonPig/RL-SSM/blob/main/RLWM_SSM_differentiable.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRLyVFDSKhgj"
      },
      "outputs": [],
      "source": [
        "!pip install 'pymc>=5.9'\n",
        "!pip install numpyro\n",
        "!pip install git+https://github.com/AlexanderFengler/ssm-simulators@main\n",
        "!pip install git+https://github.com/AlexanderFengler/LANfactory"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pymc as pm\n",
        "import numpy as np\n",
        "import random, pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pytensor\n",
        "import pytensor.tensor as pt\n",
        "import arviz as az\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import ssms\n",
        "from ssms.basic_simulators.simulator import simulator\n",
        "import lanfactory"
      ],
      "metadata": {
        "id": "GWM0hvr8KxTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "random.seed(0)"
      ],
      "metadata": {
        "id": "jAqPunB5QLlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SSM for PyTensor Pre-Prep"
      ],
      "metadata": {
        "id": "x7yJSsXtgOwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ssms.config.model_config.keys()"
      ],
      "metadata": {
        "id": "DVe-xajjydVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ssms_model = 'lba_angle_3_v1'\n",
        "model_config = ssms.config.model_config[ssms_model]\n",
        "param_theta = np.array([0.5, 0.3, 0.2, 0.5, 0.2, 0.0])\n",
        "res = simulator(\n",
        "                param_theta,\n",
        "                model=ssms_model,\n",
        "                n_samples=2000,\n",
        "                delta_t=0.001,\n",
        "                max_t=5,\n",
        "                )\n",
        "network_config = pickle.load(open('/content/drive/MyDrive/hssm_rlwm/LANs/lba_angle_3_v1_torch__network_config.pickle', 'rb'))\n",
        "model_file_path = '/content/drive/MyDrive/hssm_rlwm/LANs/lba_angle_3_v1_torch_state_dict.pt'\n",
        "torch_mlp = lanfactory.trainers.torch_mlp.LoadTorchMLPInfer(model_file_path = model_file_path,\n",
        "                                                network_config = network_config,\n",
        "                                                input_dim = 6 + 2) ## 6 is a hard-coded value for lba_angle_3_v1"
      ],
      "metadata": {
        "id": "QcyubNNtQSZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_0 = torch_mlp.net.state_dict()['layers.0.weight'].cpu().numpy().astype(np.float32).T\n",
        "weights_1 = torch_mlp.net.state_dict()['layers.2.weight'].cpu().numpy().astype(np.float32).T\n",
        "weights_2 = torch_mlp.net.state_dict()['layers.4.weight'].cpu().numpy().astype(np.float32).T\n",
        "weights_3 = torch_mlp.net.state_dict()['layers.6.weight'].cpu().numpy().astype(np.float32).T\n",
        "biases_0 = torch_mlp.net.state_dict()['layers.0.bias'].cpu().numpy().astype(np.float32).T\n",
        "biases_1 = torch_mlp.net.state_dict()['layers.2.bias'].cpu().numpy().astype(np.float32).T\n",
        "biases_2 = torch_mlp.net.state_dict()['layers.4.bias'].cpu().numpy().astype(np.float32).T\n",
        "biases_3 = torch_mlp.net.state_dict()['layers.6.bias'].cpu().numpy().astype(np.float32).T"
      ],
      "metadata": {
        "id": "uMEWZYXca4rP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zVA4Nq2J4Jr"
      },
      "source": [
        "##PyTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk_U1m5SSsJi"
      },
      "source": [
        "####Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btpenR8nSxm6"
      },
      "outputs": [],
      "source": [
        "def rlwm_step(dC, dR, pA, pG, pP, dq_RL, dq_WM):\n",
        "    \"\"\"\n",
        "    rlwm_step: calculate a single RLWM step\n",
        "    (n_participants, n_choices, n_blocks, n_stimuli)\n",
        "    dC: Choices (data)\n",
        "    dR: Rewards (data)\n",
        "    pA: Alphas (parameter)\n",
        "    pG: Gammas (parameter)\n",
        "    pP: Phis (parameter)\n",
        "    dq_RL: RL Qs (data)\n",
        "    dq_WM: WM Qs (data)\n",
        "    \"\"\"\n",
        "    cond = pt.switch(pt.lt(dq_RL, dR), 1, 0)\n",
        "    dq_RL += (cond + (1.0 - cond) * pG) * pA * (dR - dq_RL) * dC\n",
        "    dq_WM += (cond + (1.0 - cond) * pG) * 1.0 * (dR - dq_WM) * dC\n",
        "    dq_WM += pP * (1 / dR.shape[1] - dq_WM)\n",
        "    return [dq_RL, dq_WM]\n",
        "\n",
        "def rlwm_scan(dC, dR, pA, pG, pP, dq_RL, dq_WM):\n",
        "    \"\"\"\n",
        "    rlwm_scan: calculate a RLWM Q-Values\n",
        "    (n_trials, n_participants, n_choices, n_blocks, n_stimuli)\n",
        "    dC: Choices (data)\n",
        "    dR: Rewards (data)\n",
        "    pA: Alphas (parameter)\n",
        "    pG: Gammas (parameter)\n",
        "    pP: Phis (parameter)\n",
        "    dq_RL: RL Qs (data)\n",
        "    dq_WM: WM Qs (data)\n",
        "    \"\"\"\n",
        "    ([dQ_RL, dQ_WM], _) = pytensor.scan(rlwm_step, sequences=[dC, dR, pA, pG, pP], non_sequences=[], outputs_info=[dq_RL, dq_WM])\n",
        "    shape = dC.shape\n",
        "    n_trials_m1 = shape[0]-1\n",
        "    dQ_RL = pt.subtensor.set_subtensor(pt.repeat(dq_RL.reshape((1,shape[1],shape[2],shape[3],shape[4])),shape[0],axis=0)[-n_trials_m1:], dQ_RL[:n_trials_m1])\n",
        "    dQ_WM = pt.subtensor.set_subtensor(pt.repeat(dq_WM.reshape((1,shape[1],shape[2],shape[3],shape[4])),shape[0],axis=0)[-n_trials_m1:], dQ_WM[:n_trials_m1])\n",
        "    return dQ_RL, dQ_WM\n",
        "\n",
        "\n",
        "def pytensor_softmax(Qs, pB):\n",
        "    \"\"\"\n",
        "    rlwm_softmax: calculate probabilities using a tempered softmax over Q-Values\n",
        "\n",
        "    Qs: Q-Values (data)\n",
        "    pB: Betas (parameter)\n",
        "    \"\"\"\n",
        "    shape = Qs.shape\n",
        "    tempered_qs = pt.mul(Qs,pB)\n",
        "    qs_max = pt.max(tempered_qs,axis=2)\n",
        "    qs_max = pt.repeat(qs_max.reshape((shape[0], shape[1], 1, shape[3], shape[4])), shape[2], axis=2)\n",
        "    numerator = pt.exp(tempered_qs - qs_max)\n",
        "    denominator = pt.sum(numerator, axis=2)\n",
        "    denominator = pt.repeat(denominator.reshape((shape[0], shape[1], 1, shape[3], shape[4])), shape[2], axis=2)\n",
        "    Ps = numerator / denominator\n",
        "    return Ps\n",
        "\n",
        "def rlwm_policy(dC, dq_RL, dq_WM, pB, pC, pE, pR, set_sizes):\n",
        "    weight = pR * pt.clip(pC/set_sizes, 0, 1)\n",
        "    Ps_RL = pytensor_softmax(dq_RL, pB)\n",
        "    Ps_WM = pytensor_softmax(dq_WM, pB)\n",
        "    pol = weight * Ps_WM + (1.0 - weight) * Ps_RL\n",
        "    pol_final = (1.0 - pE) * pol + pE * 1.0/dC.shape[2]\n",
        "    return pol_final\n",
        "\n",
        "def pytensor_lan(weights_0,weights_1,weights_2,weights_3,biases_0,biases_1,biases_2,biases_3,in_):\n",
        "    # neural net\n",
        "    hid0 = pt.tanh(pt.dot(in_,weights_0)+biases_0)\n",
        "    hid1 = pt.tanh(pt.dot(hid0, weights_1)+biases_1)\n",
        "    hid2 = pt.tanh(pt.dot(hid1, weights_2)+biases_2)\n",
        "    out = pt.dot(hid2, weights_3)+biases_3\n",
        "    return out\n",
        "\n",
        "def scan_to_lan(dC, pol_final):\n",
        "    trial_dim = 0\n",
        "    participant_dim = 1\n",
        "    choice_dim = 2\n",
        "    block_dim = 3\n",
        "    state_dim = 4\n",
        "    # pol_final: (n_trials, n_participants, n_choices, n_blocks, n_stimuli)\n",
        "    pol_final_reshaped = pol_final.dimshuffle((participant_dim, block_dim, trial_dim, state_dim, choice_dim)).reshape((-1, dC.shape[state_dim], dC.shape[choice_dim]))\n",
        "    dC_reshaped = dC.dimshuffle((participant_dim, block_dim, trial_dim, state_dim, choice_dim)).reshape((-1,dC.shape[state_dim],dC.shape[choice_dim]))\n",
        "    dC_padding = pt.sum(dC_reshaped,axis=2)\n",
        "    pssmV = pol_final_reshaped * pt.repeat(dC_padding.reshape((-1,dC.shape[4],1)),dC.shape[2],axis=2)\n",
        "    return pssmV.max(axis=1)\n",
        "\n",
        "def rlwmssm_likelihood(dC, dq_RL, dq_WM, pB, pC, pE, pR, set_sizes, pssmA, pssmZ, pssmT, dssmRT, dssmC, weights_0,weights_1,weights_2,weights_3,biases_0,biases_1,biases_2,biases_3):\n",
        "    \"\"\"\n",
        "    rlwm_likelihood: calculate RLWM Likelihoods from precomputed Q-Values\n",
        "\n",
        "    dC: Choices (data)\n",
        "    dq_RL: Precomputed RL Qs (data)\n",
        "    dq_WM: Precomputed WM Qs (data)\n",
        "    pB: Betas (parameter)\n",
        "    pC: Working Memory Capacities (parameter)\n",
        "    pE: Epsilons (parameter)\n",
        "    pR: Rhos (parameter)\n",
        "    set_sizes: set sizes for each participant block (data)\n",
        "    \"\"\"\n",
        "    trial_dim = 0\n",
        "    participant_dim = 1\n",
        "    choice_dim = 2\n",
        "    block_dim = 3\n",
        "    state_dim = 4\n",
        "    # pol_final: (n_trials, n_participants, n_choices, n_blocks, n_stimuli)\n",
        "    pol_final = rlwm_policy(dC, dq_RL, dq_WM, pB, pC, pE, pR, set_sizes)\n",
        "    pssmV = scan_to_lan(dC, pol_final)\n",
        "    # What do I do with choices and rts? How do I put them through the LAN with the parameters?\n",
        "    in_ = pt.concatenate([pssmV, pssmA.reshape((-1,1)), pssmZ.reshape((-1,1)), pssmT.reshape((-1,1)), dssmRT.reshape((-1,1)), dssmC.reshape((-1,1))], axis=1)\n",
        "    ll = pytensor_lan(weights_0,weights_1,weights_2,weights_3,biases_0,biases_1,biases_2,biases_3,in_)\n",
        "    dC_reshaped = dC.dimshuffle((participant_dim, block_dim, trial_dim, state_dim, choice_dim)).reshape((-1,dC.shape[state_dim],dC.shape[choice_dim]))\n",
        "    dC_padding = dC_reshaped.sum(axis=[1,2]).reshape((-1,1))\n",
        "    ll_unpadded = ll * dC_padding\n",
        "    return ll_unpadded\n",
        "    # return ll\n",
        "\n",
        "\n",
        "def rlwmssm_recovery(dq_RL, dq_WM, dC, dR, pA, pB, pC, pE, pG, pP, pR, set_sizes, pssmA, pssmZ, pssmT, dssmRT, dssmC, weights_0,weights_1,weights_2,weights_3,biases_0,biases_1,biases_2,biases_3):\n",
        "    \"\"\"\n",
        "    rlwm_likelihood: calculate RLWM Likelihoods given over a valid set of parameters and complete dataset of choices, rewards, and set sizes\n",
        "\n",
        "    dC: Choices (data)\n",
        "    dq_RL: Precomputed RL Qs (data)\n",
        "    dq_WM: Precomputed WM Qs (data)\n",
        "    pB: Betas (parameter)\n",
        "    pC: Working Memory Capacities (parameter)\n",
        "    pE: Epsilons (parameter)\n",
        "    pR: Rhos (parameter)\n",
        "    set_sizes: set sizes for each participant block (data)\n",
        "    \"\"\"\n",
        "    dq_RL, dq_WM = rlwm_scan(dC, dR, pA, pG, pP, dq_RL, dq_WM)\n",
        "    likelihood = rlwmssm_likelihood(dC, dq_RL, dq_WM, pB, pC, pE, pR, set_sizes, pssmA, pssmZ, pssmT, dssmRT, dssmC, weights_0,weights_1,weights_2,weights_3,biases_0,biases_1,biases_2,biases_3)\n",
        "    return likelihood"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjZWgiJOSyb3"
      },
      "source": [
        "####Compilers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTPXZtEOBbuZ"
      },
      "outputs": [],
      "source": [
        "def rlwm_step_compile():\n",
        "    dC3 = pt.dtensor4(\"dC3\")\n",
        "    dR3 = pt.dtensor4(\"dR3\")\n",
        "    dq_RL3 = pt.dtensor4(\"dq_RL3\")\n",
        "    dq_WM3 = pt.dtensor4(\"dq_WM3\")\n",
        "    pA3 = pt.dtensor4(\"pA3\")\n",
        "    pG3 = pt.dtensor4(\"pG3\")\n",
        "    pP3 = pt.dtensor4(\"pP3\")\n",
        "\n",
        "    dq_RL, dq_WM = rlwm_step(dC3, dR3, pA3, pG3, pP3, dq_RL3, dq_WM3)\n",
        "    rlwm_step_func = pytensor.function(inputs=[dC3, dR3, pA3, pG3, pP3, dq_RL3, dq_WM3], outputs=[dq_RL, dq_WM])\n",
        "\n",
        "    return rlwm_step_func\n",
        "\n",
        "\n",
        "def rlwm_scan_compile():\n",
        "    dC4 = pt.dtensor5(\"dC4\")\n",
        "    dR4 = pt.dtensor5(\"dR4\")\n",
        "    dq_RL3 = pt.dtensor4(\"dq_RL3\")\n",
        "    dq_WM3 = pt.dtensor4(\"dq_WM3\")\n",
        "    pA4 = pt.dtensor5(\"pA4\")\n",
        "    pG4 = pt.dtensor5(\"pG4\")\n",
        "    pP4 = pt.dtensor5(\"pP4\")\n",
        "\n",
        "    dq_RL, dq_WM = rlwm_scan(dC4, dR4, pA4, pG4, pP4, dq_RL3, dq_WM3)\n",
        "    rlwm_step_func = pytensor.function(inputs=[dC4, dR4, pA4, pG4, pP4, dq_RL3, dq_WM3], outputs=[dq_RL, dq_WM])\n",
        "\n",
        "    return rlwm_step_func\n",
        "\n",
        "\n",
        "def pytensor_softmax_compile():\n",
        "    Qs = pt.dtensor5('Qs')\n",
        "    B = pt.dtensor5('B')\n",
        "\n",
        "    Ps = pytensor_softmax(Qs, B)\n",
        "    Ps_func = pytensor.function(inputs=[Qs, B], outputs=Ps)\n",
        "\n",
        "    return Ps_func\n",
        "\n",
        "def pytensor_lan_compile():\n",
        "    weights_0 = pt.dmatrix(\"weights_0\")\n",
        "    weights_1 = pt.dmatrix(\"weights_1\")\n",
        "    weights_2 = pt.dmatrix(\"weights_2\")\n",
        "    weights_3 = pt.dmatrix(\"weights_3\")\n",
        "    biases_0 = pt.dvector(\"biases_0\")\n",
        "    biases_1 = pt.dvector(\"biases_1\")\n",
        "    biases_2 = pt.dvector(\"biases_2\")\n",
        "    biases_3 = pt.dvector(\"biases_3\")\n",
        "    in_ = pt.dmatrix('in_')\n",
        "\n",
        "    ll = pytensor_lan(weights_0,weights_1,weights_2,weights_3,biases_0,biases_1,biases_2,biases_3,in_)\n",
        "    pytensor_lan_func = pytensor.function(inputs=[weights_0,weights_1,weights_2,weights_3,biases_0,biases_1,biases_2,biases_3, in_],outputs=ll)\n",
        "    return pytensor_lan_func\n",
        "\n",
        "def scan_to_lan_compile():\n",
        "    dC = pt.dtensor5(\"dC_\")\n",
        "    pol_final = pt.dtensor5(\"pol_final\")\n",
        "\n",
        "    out = scan_to_lan(dC, pol_final)\n",
        "\n",
        "    pytensor_lan_func = pytensor.function(inputs=[dC, pol_final],outputs=out, on_unused_input='ignore')\n",
        "    return pytensor_lan_func\n",
        "\n",
        "\n",
        "def rlwmssm_likelihood_compile():\n",
        "    dC4 = pt.dtensor5(\"dC4\")\n",
        "    dq_RL4 = pt.dtensor5(\"dq_RL4\")\n",
        "    dq_WM4 = pt.dtensor5(\"dq_WM4\")\n",
        "    pB4 = pt.dtensor5(\"pB4\")\n",
        "    pC4 = pt.dtensor5(\"pC4\")\n",
        "    pE4 = pt.dtensor5(\"pE4\")\n",
        "    pR4 = pt.dtensor5(\"pR4\")\n",
        "    set_sizes = pt.dtensor5(\"set_sizes\")\n",
        "    pssmA = pt.dvector(\"pssmA\")\n",
        "    pssmZ = pt.dvector(\"pssmZ\")\n",
        "    pssmT = pt.dvector(\"pssmT\")\n",
        "    dssmC = pt.dvector(\"dssmC\")\n",
        "    dssmRT = pt.dvector(\"dssmRT\")\n",
        "    weights_0 = pt.dmatrix(\"weights_0\")\n",
        "    weights_1 = pt.dmatrix(\"weights_1\")\n",
        "    weights_2 = pt.dmatrix(\"weights_2\")\n",
        "    weights_3 = pt.dmatrix(\"weights_3\")\n",
        "    biases_0 = pt.dvector(\"biases_0\")\n",
        "    biases_1 = pt.dvector(\"biases_1\")\n",
        "    biases_2 = pt.dvector(\"biases_2\")\n",
        "    biases_3 = pt.dvector(\"biases_3\")\n",
        "    likelihood = rlwmssm_likelihood(dC4, dq_RL4, dq_WM4, pB4, pC4, pE4, pR4, set_sizes, pssmA, pssmZ, pssmT, dssmC, dssmRT, weights_0,weights_1,weights_2,weights_3,biases_0,biases_1,biases_2,biases_3)\n",
        "    rlwm_likelihood_func = pytensor.function(inputs=[dC4, dq_RL4, dq_WM4, pB4, pC4, pE4, pR4, set_sizes, pssmA, pssmZ, pssmT, dssmC, dssmRT, weights_0,weights_1,weights_2,weights_3,biases_0,biases_1,biases_2,biases_3], outputs=likelihood)\n",
        "\n",
        "    return rlwm_likelihood_func\n",
        "\n",
        "def rlwmssm_recovery_compile():\n",
        "    dq_RL = pt.dtensor4(\"dq_RL\")\n",
        "    dq_WM = pt.dtensor4(\"dq_WM\")\n",
        "    dC = pt.dtensor5(\"dC\")\n",
        "    dR = pt.dtensor5(\"dR\")\n",
        "    pA = pt.dtensor5(\"pA\")\n",
        "    pB = pt.dtensor5(\"pB\")\n",
        "    pC = pt.dtensor5(\"pC\")\n",
        "    pE = pt.dtensor5(\"pE\")\n",
        "    pG = pt.dtensor5(\"pG\")\n",
        "    pP = pt.dtensor5(\"pP\")\n",
        "    pR = pt.dtensor5(\"pR\")\n",
        "    set_sizes = pt.dtensor5(\"set_sizes\")\n",
        "    pssmA = pt.dvector(\"pssmA\")\n",
        "    pssmZ = pt.dvector(\"pssmZ\")\n",
        "    pssmT = pt.dvector(\"pssmT\")\n",
        "    dssmC = pt.dvector(\"dssmC\")\n",
        "    dssmRT = pt.dvector(\"dssmRT\")\n",
        "    weights_0 = pt.dmatrix(\"weights_0\")\n",
        "    weights_1 = pt.dmatrix(\"weights_1\")\n",
        "    weights_2 = pt.dmatrix(\"weights_2\")\n",
        "    weights_3 = pt.dmatrix(\"weights_3\")\n",
        "    biases_0 = pt.dvector(\"biases_0\")\n",
        "    biases_1 = pt.dvector(\"biases_1\")\n",
        "    biases_2 = pt.dvector(\"biases_2\")\n",
        "    biases_3 = pt.dvector(\"biases_3\")\n",
        "\n",
        "    likelihood = rlwmssm_recovery(dq_RL, dq_WM, dC, dR, pA, pB, pC, pE, pG, pP, pR, set_sizes, pssmA, pssmZ, pssmT, dssmC, dssmRT, weights_0,weights_1,weights_2,weights_3,biases_0,biases_1,biases_2,biases_3)\n",
        "    rlwm_recovery_func = pytensor.function(inputs=[dq_RL, dq_WM, dC, dR, pA, pB, pC, pE, pG, pP, pR, set_sizes, pssmA, pssmZ, pssmT, dssmC, dssmRT, weights_0,weights_1,weights_2,weights_3,biases_0,biases_1,biases_2,biases_3], outputs=likelihood)\n",
        "\n",
        "    return rlwm_recovery_func"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.max(np.repeat(np.array([0,1,2,3]),3).reshape((-1,3)),axis=1)"
      ],
      "metadata": {
        "id": "ie7ggh92j_mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tests"
      ],
      "metadata": {
        "id": "h4JspSHJgAjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rlwm_step_test():\n",
        "    n_participants = 6\n",
        "    n_choices = 3\n",
        "    n_stimuli = [4, 5, 6, 7, 8]\n",
        "    max_stimuli = max(n_stimuli)\n",
        "    n_blocks = 5\n",
        "    shape4 = (n_participants, n_choices, n_blocks, max_stimuli)\n",
        "\n",
        "    dC4_ = np.random.randint(low=0, high=n_choices, size=shape4)\n",
        "    dR4_ = np.random.randint(low=0, high=1, size=shape4)\n",
        "    pA4_ = np.ones(shape4) * 0.1\n",
        "    pG4_ = np.ones(shape4) * 0.9\n",
        "    pP4_ = np.ones(shape4) * 1.0\n",
        "    mask = np.ones(shape4)\n",
        "    cond = np.ones(shape4)\n",
        "    dQ4_ = np.ones(shape4) * 1/n_choices\n",
        "    dq_RL4_ = np.ones(shape4) * 1/n_choices\n",
        "    dq_WM4_ = np.ones(shape4) * 1/n_choices\n",
        "\n",
        "    test_func = rlwm_step_compile()\n",
        "\n",
        "    return test_func(dC4_, dR4_, pA4_, pG4_, pP4_, dq_RL4_, dq_WM4_)\n",
        "\n",
        "\n",
        "def rlwm_scan_test():\n",
        "    n_trials = 23\n",
        "    n_participants = 6\n",
        "    n_choices = 3\n",
        "    n_stimuli = [4, 5, 6, 7, 8]\n",
        "    max_stimuli = max(n_stimuli)\n",
        "    n_blocks = 5\n",
        "    shape5 = (n_trials * max_stimuli, n_participants, n_choices, n_blocks, max_stimuli)\n",
        "\n",
        "    dC5_ = np.random.randint(low=0, high=n_choices, size=shape5)\n",
        "    dR5_ = np.random.randint(low=0, high=1, size=shape5)\n",
        "    dq_RL4_ = np.ones_like(dR5_)[0] * 1 / n_choices\n",
        "    dq_WM4_ = np.ones_like(dR5_)[0] * 1 / n_choices\n",
        "    pA5_ = np.ones_like(dR5_) * 0.1\n",
        "    pG5_ = np.ones_like(dR5_) * 0.9\n",
        "    pP5_ = np.ones_like(dR5_) * 1.0\n",
        "\n",
        "    test_func = rlwm_scan_compile()\n",
        "\n",
        "    return test_func(dC5_, dR5_, pA5_, pG5_, pP5_, dq_RL4_, dq_WM4_)\n",
        "\n",
        "\n",
        "def pytensor_softmax_test():\n",
        "    n_trials = 23\n",
        "    n_participants = 6\n",
        "    n_choices = 3\n",
        "    n_stimuli = [4, 5, 6, 7, 8]\n",
        "    max_stimuli = np.max(n_stimuli)\n",
        "    n_blocks = 5\n",
        "    shape = (n_trials * max_stimuli, n_participants, n_choices, n_blocks, max_stimuli)\n",
        "\n",
        "    Qs = np.ones(shape)\n",
        "    B = np.ones_like(Qs)\n",
        "\n",
        "    test_func = pytensor_softmax_compile()\n",
        "\n",
        "    return test_func(Qs, B)\n",
        "\n",
        "def pytensor_lan_test():\n",
        "    pssmV_ = np.array([[0.6,0.2,0.2]]).reshape((-1,3))\n",
        "    pssmA_ = np.array([[0.8]]).reshape((-1,1))\n",
        "    pssmZ_ = np.array([[0.2]]).reshape((-1,1))\n",
        "    pssmT_ = np.array([[0.0]]).reshape((-1,1))\n",
        "    dssmRT_ = np.array([[0.8]]).reshape((-1,1))\n",
        "    dssmC_ = np.array([[0]]).reshape((-1,1))\n",
        "    in_ = np.tile(np.concatenate([pssmV_,pssmA_,pssmZ_,pssmT_,dssmRT_,dssmC_],axis=1).reshape((1,-1)),[10,1])\n",
        "\n",
        "    test_func = pytensor_lan_compile()\n",
        "    return test_func(weights_0,weights_1,weights_2,weights_3,biases_0,biases_1,biases_2,biases_3,in_)\n",
        "\n",
        "\n",
        "def scan_to_lan_test():\n",
        "    n_trials = 23\n",
        "    n_participants = 7\n",
        "    n_choices = 3\n",
        "    n_stimuli = [2,2,3,4,4,5]\n",
        "    max_stimuli = np.max(n_stimuli)\n",
        "    n_blocks = 6\n",
        "    shape = (n_trials * max_stimuli, n_participants, n_choices, n_blocks, max_stimuli)\n",
        "\n",
        "    # dC_ = np.eye(3)[np.random.randint(low=0, high=n_choices, size=(shape[0]*shape[1]*shape[2]*shape[3]*shape[4]))]\n",
        "    dC_ = np.zeros(shape,dtype=np.int32)\n",
        "    state = 4\n",
        "    dC_[..., state] = np.tile(np.eye(3)[np.ones((shape[0]),dtype=np.int32) * 1].reshape((-1,1,3,1)),[1,shape[1],1,shape[3]])\n",
        "    pol_final = np.tile(np.array([[0.0,0.2,0.8],\n",
        "                                  [0.1,0.3,0.6],\n",
        "                                  [0.2,0.4,0.4],\n",
        "                                  [0.3,0.5,0.2],\n",
        "                                  [0.4,0.6,0.0]]).reshape(1,1,5,1,3).transpose((0,1,4,3,2)),[shape[0],shape[1],1,shape[3],1])\n",
        "\n",
        "    test_func = scan_to_lan_compile()\n",
        "    return test_func(dC_, pol_final)\n",
        "    # return pol_final\n",
        "\n",
        "\n",
        "def rlwmssm_likelihood_test():\n",
        "    n_trials = 23\n",
        "    n_participants = 6\n",
        "    n_choices = 3\n",
        "    n_stimuli = [4, 5, 6, 7, 7]\n",
        "    max_stimuli = np.max(n_stimuli)\n",
        "    n_blocks = 5\n",
        "    shape = (n_trials * max_stimuli, n_participants, n_choices, n_blocks, max_stimuli)\n",
        "\n",
        "    dC5_ = np.zeros(shape,dtype=np.int32)\n",
        "    state = 4\n",
        "    dC5_[..., state] = np.tile(np.eye(3)[np.ones((shape[0]),dtype=np.int32) * 1].reshape((-1,1,3,1)),[1,shape[1],1,shape[3]])\n",
        "    dq_RL5_ = np.ones_like(dC5_) * 1 / n_choices\n",
        "    dq_WM5_ = np.ones_like(dC5_) * 1 / n_choices\n",
        "    pB5_ = np.ones_like(dC5_) * 1.0\n",
        "    pC5_ = np.ones_like(dC5_) * 4.0\n",
        "    pE5_ = np.ones_like(dC5_) * 0.5\n",
        "    pR5_ = np.ones_like(dC5_) * 0.8\n",
        "    set_sizes_ = np.repeat(np.tile(n_stimuli, (shape[0], shape[1], shape[2], 1)).reshape((shape[0], shape[1], shape[2], shape[3], 1)), shape[4], axis=4)\n",
        "    pssmA_ = np.ones((shape[0]*shape[1]*shape[3])) * 0.5\n",
        "    pssmZ_ = np.ones((shape[0]*shape[1]*shape[3])) * 0.5\n",
        "    pssmT_ = np.ones((shape[0]*shape[1]*shape[3])) * 0.5\n",
        "    dssmC_ = np.ones((shape[0]*shape[1]*shape[3]))\n",
        "    dssmRT_ = np.random.randint(low=1, high=100, size=(shape[0]*shape[1]*shape[3])) / 25\n",
        "    weights_0_ = weights_0\n",
        "    weights_1_ = weights_1\n",
        "    weights_2_ = weights_2\n",
        "    weights_3_ = weights_3\n",
        "    biases_0_ = biases_0\n",
        "    biases_1_ = biases_1\n",
        "    biases_2_ = biases_2\n",
        "    biases_3_ = biases_3\n",
        "\n",
        "    test_func = rlwmssm_likelihood_compile()\n",
        "\n",
        "    return test_func(dC5_, dq_RL5_, dq_WM5_, pB5_, pC5_, pE5_, pR5_, set_sizes_, pssmA_, pssmZ_, pssmT_, dssmC_, dssmRT_, weights_0_, weights_1_, weights_2_, weights_3_, biases_0_, biases_1_, biases_2_, biases_3_)\n",
        "\n",
        "\n",
        "def rlwmssm_recovery_test():\n",
        "    n_trials = 23\n",
        "    n_participants = 6\n",
        "    n_choices = 3\n",
        "    n_stimuli = [4, 5, 6, 7, 7]\n",
        "    max_stimuli = np.max(n_stimuli)\n",
        "    n_blocks = 5\n",
        "    shape = (n_trials * max_stimuli, n_participants, n_choices, n_blocks, max_stimuli)\n",
        "\n",
        "    dq_RL_ = np.ones(shape)[0] * 1.0 / n_choices\n",
        "    dq_WM_ = np.ones(shape)[0] * 1.0 / n_choices\n",
        "\n",
        "    dC_ = np.random.randint(low=0, high=n_choices, size=shape)\n",
        "    dR_ = np.random.randint(low=0, high=1, size=shape)\n",
        "    pA_ = np.ones_like(dC_) * 0.01\n",
        "    pB_ = np.ones_like(dC_) * 1.0\n",
        "    pC_ = np.ones_like(dC_) * 4.0\n",
        "    pE_ = np.ones_like(dC_) * 0.02\n",
        "    pG_ = np.ones_like(dC_) * 0.8\n",
        "    pP_ = np.ones_like(dC_) * 0.3\n",
        "    pR_ = np.ones_like(dC_) * 0.8\n",
        "    set_sizes_ = np.repeat(np.tile(n_stimuli, (shape[0], shape[1], shape[2], 1)).reshape((shape[0], shape[1], shape[2], shape[3], 1)), shape[4], axis=4)\n",
        "\n",
        "    pssmA_ = np.ones((shape[0]*shape[1]*shape[3])) * 0.5\n",
        "    pssmZ_ = np.ones((shape[0]*shape[1]*shape[3])) * 0.5\n",
        "    pssmT_ = np.ones((shape[0]*shape[1]*shape[3])) * 0.5\n",
        "    dssmC_ = np.ones((shape[0]*shape[1]*shape[3]))\n",
        "    dssmRT_ = np.random.randint(low=1, high=100, size=(shape[0]*shape[1]*shape[3])) / 25\n",
        "    weights_0_ = weights_0\n",
        "    weights_1_ = weights_1\n",
        "    weights_2_ = weights_2\n",
        "    weights_3_ = weights_3\n",
        "    biases_0_ = biases_0\n",
        "    biases_1_ = biases_1\n",
        "    biases_2_ = biases_2\n",
        "    biases_3_ = biases_3\n",
        "\n",
        "    test_func = rlwmssm_recovery_compile()\n",
        "\n",
        "    return test_func(dq_RL_, dq_WM_, dC_, dR_, pA_, pB_, pC_, pE_, pG_, pP_, pR_, set_sizes_, pssmA_, pssmZ_, pssmT_, dssmC_, dssmRT_, weights_0_, weights_1_, weights_2_, weights_3_, biases_0_, biases_1_, biases_2_, biases_3_)"
      ],
      "metadata": {
        "id": "Np9NF8wagCI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWxAMAkKTFG8"
      },
      "source": [
        "###Run Compilers and Tests here\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUIZzF7pBfZD"
      },
      "outputs": [],
      "source": [
        "rlwm_step_compile()\n",
        "dq_RL, dq_WM =  rlwm_step_test()\n",
        "dq_RL.shape, dq_WM.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYXuaCJHBpPD"
      },
      "outputs": [],
      "source": [
        "rlwm_scan_compile()\n",
        "dq_RL, dq_WM = rlwm_scan_test()\n",
        "dq_RL.shape, dq_WM.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pytensor_lan_test()"
      ],
      "metadata": {
        "id": "GUkiYxrVhWaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Px9mS9IkuAm"
      },
      "outputs": [],
      "source": [
        "pytensor_softmax_compile()\n",
        "pytensor_softmax_test().shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = scan_to_lan_test()\n",
        "out.shape"
      ],
      "metadata": {
        "id": "f7Ivz_E298BZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlJ4zUcvBv9d"
      },
      "outputs": [],
      "source": [
        "out = rlwmssm_likelihood_test()\n",
        "out.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out"
      ],
      "metadata": {
        "id": "cNLVaEQ-i737"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-s2eR_RB0XW"
      },
      "outputs": [],
      "source": [
        "rlwmssm_recovery_compile()\n",
        "rlwmssm_recovery_test().flatten().shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generate RLWM-SSM Data"
      ],
      "metadata": {
        "id": "QD6QGamSdehw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6A447EmYblqB"
      },
      "outputs": [],
      "source": [
        "def gen_trial_seq(set_size, num_rep_per_block):\n",
        "    trials = list()\n",
        "\n",
        "    for stim in np.arange(set_size):\n",
        "        trials.extend([stim]*random.choice(num_rep_per_block))\n",
        "    random.shuffle(trials)\n",
        "\n",
        "    return trials\n",
        "\n",
        "def gen_SR_map(set_size, num_actions):\n",
        "    S_R_map = {}\n",
        "    acts = np.arange(num_actions)\n",
        "\n",
        "    for stim in np.arange(set_size):\n",
        "        S_R_map[stim] = random.choice(acts)\n",
        "\n",
        "    return S_R_map\n",
        "\n",
        "def step_action(s, a, S_R_map):\n",
        "    if a == S_R_map[s]:\n",
        "        rew = 1\n",
        "    else:\n",
        "        rew = 0\n",
        "\n",
        "    return rew\n",
        "\n",
        "def softmax(q_val, beta):\n",
        "    q_val = np.array(q_val)*beta\n",
        "    q_val = q_val - np.max(q_val)\n",
        "    q_val = np.exp(q_val)\n",
        "    q_val = q_val / np.sum(q_val)\n",
        "    return q_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7D-Y4SLblqB"
      },
      "outputs": [],
      "source": [
        "def simulate_RLWM(params_list, set_size_list, num_rep_per_block, num_actions, subjs=1):\n",
        "\n",
        "    sub_list = np.arange(subjs)\n",
        "    actions = np.arange(num_actions)\n",
        "\n",
        "    sub_list_sub_id = list()\n",
        "    sub_list_block_num = list()\n",
        "    sub_list_stim = list()\n",
        "    sub_list_actions = list()\n",
        "    sub_list_reward = list()\n",
        "    sub_list_corr = list()\n",
        "    sub_list_stim_ctr = list()\n",
        "    sub_list_set_size = list()\n",
        "    sub_list_rt = list()\n",
        "\n",
        "    for subj in sub_list:\n",
        "        # RLWM parameters\n",
        "        a = params_list[0]\n",
        "        z = params_list[1]\n",
        "        theta = params_list[2]\n",
        "\n",
        "        alpha = params_list[3]\n",
        "        phi = params_list[4]\n",
        "        rho = params_list[5]\n",
        "        gamma = params_list[6]\n",
        "        epsilon = params_list[7]\n",
        "        C = params_list[8]\n",
        "\n",
        "        beta = 100\n",
        "\n",
        "        pol = np.zeros(num_actions)\n",
        "\n",
        "        for bl in range(len(set_size_list)):\n",
        "            #print(\">> block -- \", bl)\n",
        "            set_size = set_size_list[bl]\n",
        "\n",
        "            S_R_map = gen_SR_map(set_size, num_actions)\n",
        "            trials = gen_trial_seq(set_size, num_rep_per_block)\n",
        "\n",
        "            # print(trials)\n",
        "\n",
        "            q_RL = np.ones((set_size, num_actions)) * 1/num_actions\n",
        "            q_WM = np.ones((set_size, num_actions)) * 1/num_actions\n",
        "            weight = rho * min(1, C/set_size)\n",
        "\n",
        "            stim_counter = np.zeros(set_size)\n",
        "\n",
        "            for tr in np.arange(len(trials)):\n",
        "                state = trials[tr]\n",
        "                stim_counter[state] += 1\n",
        "\n",
        "                pol_RL = softmax(q_RL[state, :], beta)\n",
        "                pol_WM = softmax(q_WM[state, :], beta)\n",
        "\n",
        "                pol = weight * pol_WM + (1-weight) * pol_RL\n",
        "\n",
        "                pol_final = (1 - epsilon) * pol + epsilon * np.tile([1/num_actions], num_actions)\n",
        "\n",
        "                param_theta = [pol_final[0], pol_final[1], pol_final[2], a, z, theta] # for lba_angle_3_v1\n",
        "\n",
        "\n",
        "                res = simulator(\n",
        "                    param_theta,\n",
        "                    model='lba_angle_3_v1',\n",
        "                    n_samples=1,\n",
        "                    delta_t=0.001,\n",
        "                    max_t=5,\n",
        "                    )\n",
        "\n",
        "                rt = res['rts'][0][0]\n",
        "                action = res['choices'][0][0]\n",
        "\n",
        "\n",
        "                reward = step_action(state, action, S_R_map)\n",
        "                #print(\"\\t\\t\\tdone action\", state, action, reward)\n",
        "\n",
        "                #print(\"\\t\\t\\tupdating q\")\n",
        "                if reward == 1:\n",
        "                    sub_list_corr.append(1)\n",
        "                    q_RL[state, action] = q_RL[state, action] + alpha * (reward - q_RL[state, action])\n",
        "                    q_WM[state, action] = reward\n",
        "                elif reward == 0:\n",
        "                    sub_list_corr.append(0)\n",
        "                    q_RL[state, action] = q_RL[state, action] + gamma * alpha * (reward - q_RL[state, action])\n",
        "                    q_WM[state, action] = q_WM[state, action] + gamma * (reward - q_WM[state, action])\n",
        "                #print(\"\\t\\t\\tdone updating q\")\n",
        "                q_WM = q_WM + phi * ((1/num_actions)-q_WM)\n",
        "                #print(\"\\t\\t\\tdone WM decay\")\n",
        "\n",
        "                # store data\n",
        "                sub_list_sub_id.append(subj)\n",
        "                sub_list_block_num.append(bl)\n",
        "                sub_list_stim.append(state)\n",
        "                sub_list_actions.append(action)\n",
        "                sub_list_reward.append(reward)\n",
        "                sub_list_stim_ctr.append(stim_counter[state])\n",
        "                sub_list_set_size.append(set_size)\n",
        "                sub_list_rt.append(rt)\n",
        "        #     print(\"\\t\\t -- end trial\")\n",
        "        # print(\"\\t -- end block\")\n",
        "\n",
        "    sub_list_sub_id = np.array(sub_list_sub_id)\n",
        "    sub_list_stim = np.array(sub_list_stim)\n",
        "    sub_list_actions = np.array(sub_list_actions)\n",
        "    sub_list_reward = np.array(sub_list_reward)\n",
        "    sub_list_block_num = np.array(sub_list_block_num)\n",
        "    sub_list_corr = np.array(sub_list_corr)\n",
        "    sub_list_stim_ctr = np.array(sub_list_stim_ctr)\n",
        "    sub_list_rt = np.array(sub_list_rt)\n",
        "\n",
        "\n",
        "    sub_data = np.stack([sub_list_sub_id, sub_list_block_num, sub_list_stim, sub_list_actions, sub_list_reward, sub_list_corr, sub_list_stim_ctr, sub_list_set_size, sub_list_rt], axis=1)\n",
        "    data = pd.DataFrame(sub_data, columns=['subj_idx', 'block_num', 'stim', 'response', 'feedback', 'corr', 'stim_ctr', 'set_size', 'rt'])\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjLJGmcJblqC"
      },
      "outputs": [],
      "source": [
        "s_size = [1, 2, 3, 4, 5, 6]\n",
        "freq = [3, 4, 6, 3, 3, 3]\n",
        "\n",
        "set_size_list = []\n",
        "for i in range(len(s_size)):\n",
        "    set_size_list.extend([s_size[i]]*freq[i])\n",
        "\n",
        "np.random.shuffle(set_size_list)\n",
        "set_size_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9Q0dhfdblqC"
      },
      "outputs": [],
      "source": [
        "num_rep_per_block = [15]\n",
        "\n",
        "num_datasets = 1\n",
        "num_actions = 3\n",
        "subjs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HSpkGqdblqC"
      },
      "outputs": [],
      "source": [
        "priors_a = [0.6, 0.7]\n",
        "priors_z = [0.2, 0.3]\n",
        "priors_theta = [0.05, 0.15]\n",
        "priors_rl_alpha = [0.002, 0.008]\n",
        "priors_rl_phi = [0.30, 0.40]\n",
        "priors_rl_rho = [0.65, 0.75]\n",
        "priors_rl_gamma = [0.60, 0.90]\n",
        "priors_rl_epsilon = [0, 0.05]\n",
        "priors_rl_C = [2.5, 4]\n",
        "\n",
        "rl_a = np.random.uniform(priors_a[0], priors_a[1], subjs)\n",
        "rl_z = np.random.uniform(priors_z[0], priors_z[1], subjs)\n",
        "rl_theta = np.random.uniform(priors_theta[0], priors_theta[1], subjs)\n",
        "rl_alpha = np.random.uniform(priors_rl_alpha[0], priors_rl_alpha[1], subjs)\n",
        "rl_phi = np.random.uniform(priors_rl_phi[0], priors_rl_phi[1], subjs)\n",
        "rl_rho = np.random.uniform(priors_rl_rho[0], priors_rl_rho[1], subjs)\n",
        "rl_gamma = np.random.uniform(priors_rl_gamma[0], priors_rl_gamma[1], subjs)\n",
        "rl_epsilon = np.random.uniform(priors_rl_epsilon[0], priors_rl_epsilon[1], subjs)\n",
        "rl_C = np.random.uniform(priors_rl_C[0], priors_rl_C[1], subjs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDsg1-5eEfmz"
      },
      "outputs": [],
      "source": [
        "# specify the fixed parameters and optimization settings\n",
        "\n",
        "model_rl = 'RLWM' # the model name (must be one of the keys in model_config_rl)\n",
        "num_actions = 3 # the number of actions in the RLWM task\n",
        "beta = 100 # the inverse temperature parameter in the softmax function\n",
        "\n",
        "n_restarts = 20 # the number of random restarts for each C value during the optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLVz1e7fblqC"
      },
      "outputs": [],
      "source": [
        "file = list()\n",
        "\n",
        "for n in range(num_datasets):\n",
        "    print(\"\\n==> dataset: \", n)\n",
        "    dataset_file = {}\n",
        "\n",
        "    dataset_file['info'] = {\n",
        "                        'num_datasets': num_datasets, 'num_subj': subjs, 'num_actions': num_actions,\n",
        "                        'model_rl': model_rl,\n",
        "                        'set_size_list': set_size_list, 'num_rep_per_block': num_rep_per_block\n",
        "                        }\n",
        "\n",
        "    dataset_file['data'] = list()\n",
        "    for i in range(subjs):\n",
        "        print(\"[dataset: %d] generating subj data: %d\" % (n, i))\n",
        "\n",
        "        subj_param_rl = np.array([rl_a[i], rl_z[i], rl_theta[i], rl_alpha[i], rl_phi[i], rl_rho[i], rl_gamma[i], rl_epsilon[i], rl_C[i]])\n",
        "        print(\"\\t --\", subj_param_rl)\n",
        "\n",
        "        subj_data = {}\n",
        "\n",
        "        sim_data = simulate_RLWM(subj_param_rl, set_size_list, num_rep_per_block, num_actions=num_actions, subjs=1)\n",
        "        sim_data['subj_idx'] = i\n",
        "\n",
        "        subj_data['subj_idx'] = i\n",
        "        subj_data['true_param'] = subj_param_rl\n",
        "        subj_data['sim_data'] = sim_data\n",
        "\n",
        "        #print(\"\\t --\", subj_param_rl, subj_data['true_param'])\n",
        "        dataset_file['data'].append(subj_data)\n",
        "\n",
        "    file.append(dataset_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6N8EmRxblqC"
      },
      "outputs": [],
      "source": [
        "# before saving; check data using data validation code below\n",
        "# save first dataset in the datafile\n",
        "dataset_file = file[0]\n",
        "\n",
        "param_list = ['true_a', 'true_z', 'true_theta', 'true_alpha', 'true_phi', 'true_rho', 'true_gamma', 'true_epsilon', 'true_C']\n",
        "\n",
        "list_sub_data = list()\n",
        "for itr in range(len(dataset_file['data'])):\n",
        "    data = dataset_file['data'][itr]['sim_data']\n",
        "\n",
        "    for p, p_name in zip(dataset_file['data'][itr]['true_param'], param_list):\n",
        "        data[p_name] = p\n",
        "\n",
        "    data['subj_idx'] = itr\n",
        "\n",
        "    list_sub_data.append(data)\n",
        "PR_data = pd.concat(list_sub_data, ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyMC"
      ],
      "metadata": {
        "id": "4_BF9HdxeeJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Prepare data for PyTensor"
      ],
      "metadata": {
        "id": "kn55XiSTeh9B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "fss6e6hQ8Elv"
      },
      "outputs": [],
      "source": [
        "df = PR_data.sort_values(['subj_idx', 'block_num'])\n",
        "# df = df.loc[df['subj_idx'].isin([0])]\n",
        "# df = df.loc[df['block_num'].isin([0.0])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npPzhBVYUwAU",
        "outputId": "f667cdac-74e4-4d22-d7b1-8e1f133f8351"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(712800, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ],
      "source": [
        "max_trials = df[['subj_idx','block_num']].value_counts().max()\n",
        "max_stimuli = int(df['stim'].max()) + 1\n",
        "n_participants = len(df['subj_idx'].unique())\n",
        "n_choices = int(df['response'].max()) + 1\n",
        "n_blocks = len(df['block_num'].unique())\n",
        "\n",
        "\n",
        "shape = (n_participants, n_blocks, max_trials, n_choices, max_stimuli)\n",
        "pad_value = 0\n",
        "# stimuli = np.ones(shape) * -100\n",
        "stim_choices = np.ones(shape) * pad_value\n",
        "rewards = np.ones(shape) * pad_value\n",
        "rts = np.ones(shape) * pad_value\n",
        "set_sizes = np.repeat(np.array(df.groupby(['subj_idx','block_num']).mean()['set_size']),repeats=max_trials*n_choices*max_stimuli).flatten()\n",
        "subj_idxs = np.repeat(np.arange(n_participants),max_trials*n_choices*n_blocks*max_stimuli).flatten()\n",
        "block_nums = np.tile(np.repeat(np.arange(n_blocks), repeats=max_trials*n_choices*max_stimuli),n_participants).flatten()\n",
        "\n",
        "for i, subj_idx in enumerate(df['subj_idx'].unique()):\n",
        "    for j, block_num in enumerate(df['block_num'].unique()):\n",
        "\n",
        "        subj_block_data = df[(df['subj_idx'] == subj_idx) & (df['block_num'] == block_num)]\n",
        "        n_trials = subj_block_data.shape[0]\n",
        "        subj_block_stimuli = subj_block_data['stim'].to_numpy(dtype=np.int32)\n",
        "        n_stimuli = subj_block_stimuli.max() + 1\n",
        "        subj_block_choices = subj_block_data['response'].to_numpy(dtype=np.int32)\n",
        "        subj_block_rewards = subj_block_data['feedback'].to_numpy(dtype=np.float32)\n",
        "        subj_block_rts = subj_block_data['rt'].to_numpy(dtype=np.float32)\n",
        "\n",
        "        subj_stimuli_stim_choices = np.stack([subj_block_stimuli, subj_block_choices], axis=-1)\n",
        "\n",
        "        onehot_stim_choices = np.zeros((n_trials, n_choices, n_stimuli))\n",
        "        for t in range(n_trials):\n",
        "            stim = subj_block_stimuli[t]\n",
        "            choice = subj_block_choices[t]\n",
        "            onehot_stim_choices[t,choice,stim] = 1\n",
        "\n",
        "        # subj_stimuli_stim_choices = np.eye([n_choices, max_stimuli])[subj_stimuli_stim_choices]\n",
        "        #subj_block_stimuli = np.eye(max_stimuli)[subj_block_stimuli]\n",
        "        #subj_block_choices = np.eye((n_choices, max_stimuli))[subj_block_choices]\n",
        "        subj_block_rewards = subj_block_rewards.reshape((n_trials, 1, 1)).repeat(n_choices, axis=1).repeat(n_stimuli, axis=2)\n",
        "        subj_block_rts = subj_block_rts.reshape((n_trials, 1, 1)).repeat(n_choices, axis=1).repeat(n_stimuli, axis=2)\n",
        "\n",
        "        # stimuli[subj_idx, int(block_num), :n_trials, :, :] = subj_block_stimuli\n",
        "        stim_choices[i, j, :n_trials, :, :n_stimuli] = onehot_stim_choices\n",
        "        rewards[i, j, :n_trials, :, :n_stimuli] = subj_block_rewards\n",
        "        rts[i, j, :n_trials, :, :n_stimuli] = subj_block_rts\n",
        "\n",
        "\n",
        "\n",
        "padded_ohe_df = pd.DataFrame(data={'subj_idx': subj_idxs,\n",
        "                               'block_num': block_nums,\n",
        "                               'response': stim_choices.flatten(),\n",
        "                               'feedback': rewards.flatten(),\n",
        "                               'rt': rts.flatten(),\n",
        "                               'set_size': set_sizes,\n",
        "                               })\n",
        "padded_ohe_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###PyMC Wrapper and Compile"
      ],
      "metadata": {
        "id": "4isrnx5_e4qP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "EH_fwWmv5pen"
      },
      "outputs": [],
      "source": [
        "n_trials, n_participants, n_choices, n_blocks, max_stimuli = (max_trials, n_participants, n_choices, n_blocks, max_stimuli)\n",
        "\n",
        "def rlwmssm_hdll(pA_, pB_, pC_, pE_, pG_, pP_, pR_, choices, rewards, set_sizes_, pssmA_, pssmZ_, pssmT_, df_rts_, df_choices_, weights_0__,weights_1__,weights_2__,weights_3__,biases_0__,biases_1__,biases_2__,biases_3__):\n",
        "    inner_shape = (n_participants, n_choices, n_blocks, max_stimuli)\n",
        "    full_shape = (inner_shape[0], inner_shape[2], n_trials, inner_shape[1], inner_shape[3])\n",
        "    dq_RL_ = pt.ones(inner_shape) / n_choices\n",
        "    dq_WM_ = pt.ones(inner_shape) / n_choices\n",
        "\n",
        "    dC_ = choices.reshape(full_shape).dimshuffle((2,0,3,1,4))\n",
        "    dR_ = rewards.reshape(full_shape).dimshuffle((2,0,3,1,4))\n",
        "    set_sizes_ = set_sizes_.reshape(full_shape).dimshuffle((2,0,3,1,4))\n",
        "\n",
        "    pA_ = pA_.reshape(full_shape).dimshuffle((2,0,3,1,4))\n",
        "    pB_ = pB_.reshape(full_shape).dimshuffle((2,0,3,1,4))\n",
        "    pC_ = pC_.reshape(full_shape).dimshuffle((2,0,3,1,4))\n",
        "    pE_ = pE_.reshape(full_shape).dimshuffle((2,0,3,1,4))\n",
        "    pG_ = pG_.reshape(full_shape).dimshuffle((2,0,3,1,4))\n",
        "    pP_ = pP_.reshape(full_shape).dimshuffle((2,0,3,1,4))\n",
        "    pR_ = pR_.reshape(full_shape).dimshuffle((2,0,3,1,4))\n",
        "\n",
        "    return rlwmssm_recovery(dq_RL_, dq_WM_, dC_, dR_, pA_, pB_, pC_, pE_, pG_, pP_, pR_, set_sizes_, pssmA_, pssmZ_, pssmT_, df_rts_, df_choices_, weights_0__,weights_1__,weights_2__,weights_3__,biases_0__,biases_1__,biases_2__,biases_3__).flatten()\n",
        "    #return rlwmssm_Ps(dq_RL_, dq_WM_, dC_, dR_, pA_, pB_, pG_, pP_)\n",
        "    #return rlwm_scan(dC_, dR_, pA_, pG_, pP_, dq_RL_, dq_WM_)\n",
        "\n",
        "pA = pt.dvector()\n",
        "pB = pt.dvector()\n",
        "pC = pt.dvector()\n",
        "pE = pt.dvector()\n",
        "pG = pt.dvector()\n",
        "pP = pt.dvector()\n",
        "pR = pt.dvector()\n",
        "choices__ = pt.dvector()\n",
        "rewards__ = pt.dvector()\n",
        "set_sizes__ = pt.dvector()\n",
        "df_rts__ = pt.dvector()\n",
        "df_choices__ = pt.dvector()\n",
        "pssmA__ = pt.dvector()\n",
        "pssmZ__ = pt.dvector()\n",
        "pssmT__ = pt.dvector()\n",
        "weights_0__ = pt.dmatrix()\n",
        "weights_1__ = pt.dmatrix()\n",
        "weights_2__ = pt.dmatrix()\n",
        "weights_3__ = pt.dmatrix()\n",
        "biases_0__ = pt.dvector()\n",
        "biases_1__ = pt.dvector()\n",
        "biases_2__ = pt.dvector()\n",
        "biases_3__ = pt.dvector()\n",
        "\n",
        "output = rlwmssm_hdll(pA, pB, pC, pE, pG, pP, pR, choices__, rewards__, set_sizes__, pssmA__, pssmZ__, pssmT__, df_rts__, df_choices__, weights_0__,weights_1__,weights_2__,weights_3__,biases_0__,biases_1__,biases_2__,biases_3__)\n",
        "\n",
        "my_rlwmssm_hdll_func = pytensor.function(inputs=[pA, pB, pC, pE, pG, pP, pR, choices__, rewards__, set_sizes__, pssmA__, pssmZ__, pssmT__, df_rts__, df_choices__, weights_0__,weights_1__,weights_2__,weights_3__,biases_0__,biases_1__,biases_2__, biases_3__], outputs=output, on_unused_input='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "lkxHdL8qBBL3"
      },
      "outputs": [],
      "source": [
        "pA_ = np.ones(padded_ohe_df.shape[0]).flatten() * rl_alpha[0]\n",
        "pB_ = np.ones(padded_ohe_df.shape[0]).flatten() * 100\n",
        "pC_ = np.ones(padded_ohe_df.shape[0]).flatten() * rl_C[0]\n",
        "pE_ = np.ones(padded_ohe_df.shape[0]).flatten() * rl_epsilon[0]\n",
        "pG_ = np.ones(padded_ohe_df.shape[0]).flatten() * rl_gamma[0]\n",
        "pP_ = np.ones(padded_ohe_df.shape[0]).flatten() * rl_phi[0]\n",
        "pR_ = np.ones(padded_ohe_df.shape[0]).flatten() * rl_rho[0]\n",
        "pssmA_ = np.ones((padded_ohe_df.shape[0]//n_choices)//max_stimuli).flatten() * rl_a[0]\n",
        "pssmZ_ = np.ones((padded_ohe_df.shape[0]//n_choices)//max_stimuli).flatten() * rl_z[0]\n",
        "pssmT_ = np.ones((padded_ohe_df.shape[0]//n_choices)//max_stimuli).flatten() * rl_theta[0]\n",
        "choices_ = padded_ohe_df['response'].to_numpy(dtype=np.int32)\n",
        "rewards_ = padded_ohe_df['feedback'].to_numpy(dtype=np.float32)\n",
        "set_sizes_ = padded_ohe_df['set_size'].to_numpy(dtype=np.float32)\n",
        "df_choices_ = np.max(np.argmax(padded_ohe_df['response'].to_numpy(dtype=np.int32).reshape((-1,n_choices,max_stimuli)),axis=1),axis=1)\n",
        "df_rts_ = np.max(np.max(padded_ohe_df['rt'].to_numpy(dtype=np.float32).reshape((-1,n_choices,max_stimuli)),axis=1),axis=1)\n",
        "weights_0_ = weights_0\n",
        "weights_1_ = weights_1\n",
        "weights_2_ = weights_2\n",
        "weights_3_ = weights_3\n",
        "biases_0_ = biases_0\n",
        "biases_1_ = biases_1\n",
        "biases_2_ = biases_2\n",
        "biases_3_ = biases_3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###PyTensor Python Comparison"
      ],
      "metadata": {
        "id": "tMMAdYOHe7T7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def call_LAN(LAN_matrix):\n",
        "    net_input = np.array(LAN_matrix).astype(np.float32)\n",
        "    LL = torch_mlp.predict_on_batch(net_input)\n",
        "    return np.sum(LL)"
      ],
      "metadata": {
        "id": "VQTNPg8p3h62"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RLWM_LL(params, subj_data, model_ssm, num_actions, beta):\n",
        "\n",
        "    a = params[0]\n",
        "    z = params[1]\n",
        "    theta = params[2]\n",
        "\n",
        "    alpha = params[3]\n",
        "    phi = params[4]\n",
        "    rho = params[5]\n",
        "    gamma = params[6]\n",
        "    epsilon = params[7]\n",
        "    C = params[8]\n",
        "\n",
        "    if a < 0.1 or a > 1.0:\n",
        "        return np.inf\n",
        "\n",
        "    if z < 0 or z >= a or z > 0.45:\n",
        "        return np.inf\n",
        "\n",
        "    if theta < 0 or theta > 1.2:\n",
        "        return np.inf\n",
        "\n",
        "    if alpha < 0 or alpha > 0.1: # CHECK\n",
        "        return np.inf\n",
        "\n",
        "    if phi < 0 or phi > 1.0: # CHECK\n",
        "        return np.inf\n",
        "\n",
        "    if rho < 0.0 or rho > 1: # CHECK\n",
        "        return np.inf\n",
        "\n",
        "    if gamma < 0.0 or gamma > 1.0:\n",
        "        return np.inf\n",
        "\n",
        "    if epsilon < 0 or epsilon > 0.1: # CHECK\n",
        "        return np.inf\n",
        "\n",
        "    if C < 2 or C > 5:\n",
        "        return np.inf\n",
        "\n",
        "    actions = np.arange(num_actions)\n",
        "    pol = np.zeros(num_actions)\n",
        "\n",
        "    block_list = np.unique(subj_data['block_num'])\n",
        "\n",
        "    LAN_matrix = np.zeros((len(subj_data['rt']), len(ssms.config.model_config[model_ssm]['params']) + 2))\n",
        "    subj_trl_idx = 0\n",
        "\n",
        "    for bl in block_list:\n",
        "        #print(\">> block -- \", bl, len(np.unique(subj_data.loc[subj_data['block_num'] == bl]['stim'])))\n",
        "\n",
        "        block_data = subj_data.loc[subj_data['block_num'] == bl]\n",
        "\n",
        "        set_size = len(np.unique(block_data['stim']))\n",
        "\n",
        "        trials = block_data['stim'].values\n",
        "        reward_list = block_data['feedback'].values\n",
        "        action_list = block_data['response'].values\n",
        "        rt_list = block_data['rt'].values\n",
        "\n",
        "        q_RL = np.ones((set_size, num_actions)) * 1/num_actions\n",
        "        q_WM = np.ones((set_size, num_actions)) * 1/num_actions\n",
        "        weight = rho * min(1, C/set_size)\n",
        "\n",
        "        for tr in np.arange(len(trials)):\n",
        "            state = int(trials[tr])\n",
        "\n",
        "            pol_RL = softmax(q_RL[state, :], beta)\n",
        "            pol_WM = softmax(q_WM[state, :], beta)\n",
        "\n",
        "            pol = weight * pol_WM + (1-weight) * pol_RL\n",
        "\n",
        "            pol_final = (1 - epsilon) * pol + epsilon * np.tile([1/num_actions], num_actions)\n",
        "\n",
        "            #print(\">> \", np.sum(pol_RL), np.sum(pol_WM), np.sum(pol), np.sum(pol_final), pol, pol_final)\n",
        "\n",
        "            action = int(action_list[tr])\n",
        "            reward = reward_list[tr]\n",
        "\n",
        "            if (reward - q_RL[state, action]) >= 0:\n",
        "                q_RL[state, action] = q_RL[state, action] + alpha * (reward - q_RL[state, action])\n",
        "                q_WM[state, action] = q_WM[state, action] + 1 * (reward - q_WM[state, action])\n",
        "            else:\n",
        "                q_RL[state, action] = q_RL[state, action] + gamma * alpha * (reward - q_RL[state, action])\n",
        "                q_WM[state, action] = q_WM[state, action] + gamma * 1 * (reward - q_WM[state, action])\n",
        "\n",
        "            q_WM = q_WM + phi * ((1/num_actions)-q_WM)\n",
        "\n",
        "            LAN_matrix[subj_trl_idx, :] = np.array([pol_final[0], pol_final[1], pol_final[2], a, z, theta, rt_list[tr], action])\n",
        "            subj_trl_idx += 1\n",
        "    #print(LAN_matrix)\n",
        "    subj_ll = call_LAN(LAN_matrix) # Call LAN here\n",
        "\n",
        "    return -subj_ll"
      ],
      "metadata": {
        "id": "1ClgPe-r3oZV"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhENkdWjMhhc",
        "outputId": "dcbc3729-a6e0-4313-eae8-7e360de41f45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11963.864854552201"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ],
      "source": [
        "#my_rlwm_hdll_func(pA_, pB_, pC_, pE_, pG_, pP_, pR_, choices_, rewards_, set_sizes_).sum()\n",
        "my_rlwmssm_hdll_func(pA_, pB_, pC_, pE_, pG_, pP_, pR_, choices_, rewards_, set_sizes_, pssmA_, pssmZ_, pssmT_, df_rts_, df_choices_, weights_0_,weights_1_,weights_2_,weights_3_,biases_0_,biases_1_,biases_2_,biases_3_).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Upy4HSBmqjSV",
        "outputId": "409bd1bc-6367-44aa-e5a3-f9787f7ed1ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-11963.864013671875"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ],
      "source": [
        "ll = 0\n",
        "for subj_idx in df['subj_idx'].unique():\n",
        "  ll += RLWM_LL((pssmA_[0],pssmZ_[0],pssmT_[0], pA_[0], pP_[0], pR_[0], pG_[0], pE_[0], pC_[0]), df.loc[df['subj_idx']==subj_idx], ssms_model, n_choices, pB_[0])\n",
        "# ll, Qs = RLWM_LL((pA_[0], pP_[0], pR_[0], pG_[0], pE_[0]), df, 3, pC_[0], pB_[0])\n",
        "ll"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Run PyMC"
      ],
      "metadata": {
        "id": "pejPRWusfubr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "4deb8c856a4c444db3a91a8237293267",
            "e469368595fc480f8eb03d53713eba47",
            "a4fd62750b61486c99c25c7adeabbe06",
            "0530f83c731a46c8ac7386475f79d38d",
            "d2676737ec9244f9b742cd8b572e9011",
            "8d685fc29fdc42b3a65f223bb18d8555",
            "d5e49545e0ca4729b767e741e2e2b817",
            "a30139d5583a42888be334adb254c1e2",
            "9fb7da58202f4f3991a81cc595d17bfb",
            "af3018095f5f40348a50a05f9ab4136f",
            "050d5d274e4a4580b67e38fdb40b4155",
            "5b518233732b44379fe5285ef6d66f44",
            "3b8041164e074fcd884c49b777828d5a",
            "7c2a9aab0347404a9de051c7c4bb3b65",
            "dcb329882d8142e6bc33da393083454c",
            "81418e8900c84ac9bb9cef49e10f5b88",
            "9dd7660aaed24b1086421f59b6089230",
            "5c5e0d44f88443848ab724a2786ac765",
            "6f9010b001dc47c9b78a1fdb93489f50",
            "d006819af7c0400ebfb0289b3012cabe",
            "e051fee817104031b8333898d6349a12",
            "fdda78dc3259483f993349e284c0b6ea",
            "0e012e3ca58d43038fff96ed2e0bdcbd",
            "e7ea6c2ffb67421fb4260e4d8c39554c",
            "fe166430f39b42af8c009cb846995a32",
            "345b4134cb10431db5542bff84017fbf",
            "c27104a50bab459a8b0252799607c8aa",
            "baae53156838460a8f0b7bc5f5a82963",
            "e1ba5a4a0c1b43d58c1d42468e8164e7",
            "abd051d4a81046e4a2e6acfd6d917e3b",
            "6d01e552ea824399aa8f8768bc904107",
            "e451e1b75f1a4fa78970a6343552b6f4",
            "7db57ced51dc49e88c6ba3af8766c439",
            "3f37cdbf720e4abfbe6558411d675f2f",
            "ded87cbd0bf14fb38a6e874c56bae6c4",
            "2059bd34141c43f9b14d9ced2af6199a",
            "84e0a647eb554186943bd0832eeabb4e",
            "2202a79596264411a2cffb3788f2ddaf",
            "9d4254de03fa4ef6bc180c4651e513d6",
            "41843d4f914c47f7acd3e47e3089f84e",
            "cb81f6fbc55a4bffbff2e5039c9c257a",
            "8b67a71e77de435e958176489a1d6333",
            "62e0c967038044b78afba6c487f93e04",
            "5e82c682265a46a3838ccad633eaf87e"
          ]
        },
        "id": "X-7hleDBp4QG",
        "outputId": "d98a91dd-9223-4699-ad26-e9584831517a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pymc.sampling.mcmc:Only 10 samples in chain.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4deb8c856a4c444db3a91a8237293267"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b518233732b44379fe5285ef6d66f44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e012e3ca58d43038fff96ed2e0bdcbd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f37cdbf720e4abfbe6558411d675f2f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Make coordinates\n",
        "participant_ids, participants = pd.factorize(padded_ohe_df['subj_idx'])\n",
        "coords = {\n",
        "          \"participant_idx\": np.array(participants),\n",
        "          \"obs_idx\": np.arange(padded_ohe_df.shape[0])\n",
        "         }\n",
        "\n",
        "with pm.Model(coords=coords) as hierarchical_model:\n",
        "    # Data\n",
        "    #Choices = pm.ConstantData('Choices', padded_ohe_df['response'].to_numpy())\n",
        "    #Rewards = pm.ConstantData('Rewards', padded_ohe_df['feedback'].to_numpy())\n",
        "    #Set_sizes = pm.ConstantData('Set_sizes', padded_ohe_df['set_size'].to_numpy())\n",
        "    Choices = pm.ConstantData('Choices', choices_)\n",
        "    Rewards = pm.ConstantData('Rewards', rewards_)\n",
        "    Set_sizes = pm.ConstantData('Set_sizes', set_sizes_)\n",
        "    DF_choices = pm.ConstantData('DF_choices', df_choices_)\n",
        "    DF_rts = pm.ConstantData('DF_rts', df_rts_)\n",
        "    # Hyperpriors for group nodes\n",
        "    # pA_alpha = 3 # pm.Gamma(\"pA_alpha\", alpha = 3. , beta = 3.)\n",
        "    # pA_beta = 3 # pm.Gamma(\"pA_beta\", alpha = 3. , beta = 3.)\n",
        "    # # pB_alpha = 3 # pm.Gamma(\"pB_alpha\", alpha = 3. , beta = 3.)\n",
        "    # # pB_beta = 3 # pm.Gamma(\"pB_beta\", alpha = 3. , beta = 3.)\n",
        "    # pC_alpha = 3 # pm.Gamma(\"pC_alpha\", alpha = 3. , beta = 3.)\n",
        "    # pC_beta = 3 # pm.Gamma(\"pC_beta\", alpha = 3. , beta = 3.)\n",
        "    # pE_alpha = 3 # pm.Gamma(\"pE_alpha\", alpha = 3. , beta = 3.)\n",
        "    # pE_beta = 3 # pm.Gamma(\"pE_beta\", alpha = 3. , beta = 3.)\n",
        "    # pG_alpha = 3 # pm.Gamma(\"pG_alpha\", alpha = 3. , beta = 3.)\n",
        "    # pG_beta = 3 # pm.Gamma(\"pG_beta\", alpha = 3. , beta = 3.)\n",
        "    # pP_alpha = 3 # pm.Gamma(\"pP_alpha\", alpha = 3. , beta = 3.)\n",
        "    # pP_beta = 3 # pm.Gamma(\"pP_beta\", alpha = 3. , beta = 3.)\n",
        "    # pR_alpha = 3 # pm.Gamma(\"pR_alpha\", alpha = 3. , beta = 3.)\n",
        "    # pR_beta = 3 # pm.Gamma(\"pR_beta\", alpha = 3. , beta = 3.)\n",
        "\n",
        "    # priors_rl_alpha = [0,0.01] # [0, 0.01]\n",
        "    # priors_rl_phi = [0.30,0.30]# [0, 0.40]\n",
        "    # priors_rl_rho = [0.8,0.8] # [0.75, 1]\n",
        "    # priors_rl_gamma =[0.7,0.7] # [0.60, 0.90]\n",
        "    # priors_rl_epsilon = [0.01,0.01] # [0, 0.05]\n",
        "    # priors_rl_C = [3,3] # [2, 5]\n",
        "\n",
        "\n",
        "    # Priors for variables\n",
        "    # pA = pm.ConstantData('pA', np.ones_like(choices_) * rl_alpha[0])\n",
        "    pB = pm.ConstantData('pB', np.ones_like(choices_) * 100.0)\n",
        "    # pC = pm.ConstantData('pC', np.ones_like(choices_) * rl_C[0])\n",
        "    # pE = pm.ConstantData('pE', np.ones_like(choices_) * rl_epsilon[0])\n",
        "    # pG = pm.ConstantData('pG', np.ones_like(choices) * rl_gamma[0])\n",
        "    # pP = pm.ConstantData('pP', np.ones_like(choices_) * rl_phi[0])\n",
        "    # pR = pm.ConstantData('pR', np.ones_like(choices_) * rl_rho[0])\n",
        "    pssmA = pm.ConstantData('pssmA', pssmA_)\n",
        "    pssmZ = pm.ConstantData('pssmZ', pssmZ_)\n",
        "    pssmT = pm.ConstantData('pssmT', pssmT_)\n",
        "    pA = pm.Beta(name='pA', alpha=2.0, beta=100, dims=\"participant_idx\")#, initval=np.array(pA_[0]).reshape((-1,)))\n",
        "    # pB = pm.Uniform(name=\"pB\", lower=0.8, upper=1.2, dims=\"participant_idx\")\n",
        "    pC = pm.TruncatedNormal(name=\"pC\", mu=3.0, sigma=0.25, lower=2.0, upper=5.0, dims=\"participant_idx\")#, initval=np.array(pC_[0]).reshape((-1,)))\n",
        "    pE = pm.TruncatedNormal(name=\"pE\", mu=0.01, sigma=0.001, lower=0.0, upper=1.0, dims=\"participant_idx\")\n",
        "    pG = pm.TruncatedNormal(name=\"pG\", mu=0.1, sigma=0.01, lower=0.0, upper=1.0, dims=\"participant_idx\")#, initval=np.array(pG_[0]).reshape((-1,)))\n",
        "    pP = pm.TruncatedNormal(name=\"pP\",  mu=0.3, sigma=0.025, lower=0.0, upper=1.0, dims=\"participant_idx\")#, initval=np.array(pP_[0]).reshape((-1,)))\n",
        "    pR = pm.TruncatedNormal(name=\"pR\",  mu=0.8, sigma=0.025, lower=0.0, upper=1.0, dims=\"participant_idx\")#, initval=np.array(pR_[0]).reshape((-1,)))\n",
        "    # pA = pm.Beta(name=\"pA\", alpha=pA_alpha, beta=pA_beta, dims=\"participant_idx\")\n",
        "    # pB = pm.Beta(name=\"pB\", alpha=pB_alpha, beta=pB_beta, dims=\"participant_idx\")\n",
        "    # pC = pm.Beta(name=\"pC\", alpha=pC_alpha, beta=pC_beta, dims=\"participant_idx\")\n",
        "    # pE = pm.Beta(name=\"pE\", alpha=pE_alpha, beta=pE_beta, dims=\"participant_idx\")\n",
        "    # pG = pm.Beta(name=\"pG\", alpha=pG_alpha, beta=pG_beta, dims=\"participant_idx\")\n",
        "    # pP = pm.Beta(name=\"pP\", alpha=pP_alpha, beta=pP_beta, dims=\"participant_idx\")\n",
        "    # pR = pm.Beta(name=\"pR\", alpha=pR_alpha, beta=pR_beta, dims=\"participant_idx\")\n",
        "\n",
        "\n",
        "    # Render parameters trial wise\n",
        "    pA_trial = pA[participant_ids]\n",
        "    # pB_trial = pB[participant_ids]\n",
        "    pC_trial = pC[participant_ids]\n",
        "    # pE_trial = pE[participant_ids]\n",
        "    pG_trial = pG[participant_ids]\n",
        "    pP_trial = pP[participant_ids]\n",
        "    pR_trial = pR[participant_ids]\n",
        "    # pA_trial = pA\n",
        "    pB_trial = pB\n",
        "    #pC_trial = pC\n",
        "    pE_trial = pE\n",
        "    # pG_trial = pG\n",
        "    #pP_trial = pP\n",
        "    #pR_trial = pR\n",
        "\n",
        "    # CHOOSE WHICH WRAPPER FUNCTION TO USE HERE\n",
        "    pm.Potential(\"log_likelihood\",\n",
        "                 my_rlwmssm_hdll_func(pA_, pB_, pC_, pE_, pG_, pP_, pR_, choices_, rewards_, set_sizes_,\n",
        "                                      pssmA_, pssmZ_, pssmT_, df_choices_, df_rts_,\n",
        "                                      weights_0_,weights_1_,weights_2_,weights_3_,biases_0_,biases_1_,biases_2_,biases_3_))\n",
        "    idata_pooled = pm.sample(1000, tune=1000, chains=4, nuts_sampler=\"numpyro\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "az.plot_trace(idata_pooled, lines=[\n",
        "    (\"pA\", {}, rl_alpha),\n",
        "    (\"pC\", {}, rl_C),\n",
        "    (\"pE\", {}, rl_epsilon),\n",
        "    (\"pG\", {}, rl_gamma),\n",
        "    (\"pP\", {}, rl_phi),\n",
        "    (\"pR\", {}, rl_rho),\n",
        "])"
      ],
      "metadata": {
        "id": "OGv_OeLcf4tG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}